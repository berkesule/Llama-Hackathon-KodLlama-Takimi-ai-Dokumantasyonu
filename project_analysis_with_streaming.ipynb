{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko2v8-fXwS8_",
        "outputId": "8a12eac4-8e09-42e8-9ada-cc5e4392b439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ht72h9oKwME8",
        "outputId": "d1823b50-0233-4942-e17b-eef1cb66887f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vllm\n",
            "  Downloading vllm-0.11.0-cp38-abi3-manylinux1_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm) (2024.11.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.55.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.57.1)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.119.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm) (3.13.1)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.109.1)\n",
            "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.11.10)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm) (11.3.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.0)\n",
            "Collecting lm-format-enforcer==0.11.3 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
            "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting outlines_core==0.2.11 (from vllm)\n",
            "  Downloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting diskcache==5.6.3 (from vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.25 (from vllm)\n",
            "  Downloading xgrammar-0.1.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.20.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from vllm)\n",
            "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\n",
            "Collecting setuptools<80,>=77.0.3 (from vllm)\n",
            "  Downloading setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.1)\n",
            "Collecting compressed-tensors==0.11.0 (from vllm)\n",
            "  Downloading compressed_tensors-0.11.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.19.0 (from vllm)\n",
            "  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.1)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm) (1.16.2)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pybase64 (from vllm)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting cbor2 (from vllm)\n",
            "  Downloading cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting setproctitle (from vllm)\n",
            "  Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Collecting openai-harmony>=0.0.3 (from vllm)\n",
            "  Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n",
            "  Downloading ray-2.50.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torchaudio==2.8.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.0+cu126)\n",
            "Collecting xformers==0.0.32.post1 (from vllm)\n",
            "  Downloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.11.0->vllm) (2.4.6)\n",
            "Collecting astor (from depyf==0.19.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\n",
            "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm) (25.0)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.48.0)\n",
            "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.14-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.38.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.25.1)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (0.4.2)\n",
            "Collecting click!=8.3.0,>=7.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm) (0.35.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.2->vllm) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.22.0)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.20.0)\n",
            "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.1->vllm) (1.1.10)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.27.1)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\n",
            "Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.0.0)\n",
            "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rignore-0.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.42.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading vllm-0.11.0-cp38-abi3-manylinux1_x86_64.whl (438.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.2/438.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.11.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.19.0-py3-none-any.whl (39 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading ray-2.50.1-cp312-cp312-manylinux2014_x86_64.whl (71.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
            "Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading fastapi_cli-0.0.14-py3-none-any.whl (11 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_cloud_cli-0.3.1-py3-none-any.whl (19 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
            "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rignore-0.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (951 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.9/951.9 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, setuptools, setproctitle, rignore, pyngrok, pycountry, pybase64, partial-json-parser, outlines_core, ninja, msgspec, llvmlite, llguidance, lark, interegular, httptools, gguf, dnspython, diskcache, click, cbor2, blake3, astor, watchfiles, numba, email-validator, depyf, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, lm-format-enforcer, xformers, ray, fastapi-cloud-cli, fastapi-cli, xgrammar, mistral_common, compressed-tensors, vllm\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: lark\n",
            "    Found existing installation: lark 1.3.0\n",
            "    Uninstalling lark-1.3.0:\n",
            "      Successfully uninstalled lark-1.3.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astor-0.8.1 blake3-1.0.8 cbor2-5.7.1 click-8.2.1 compressed-tensors-0.11.0 depyf-0.19.0 diskcache-5.6.3 dnspython-2.8.0 email-validator-2.3.0 fastapi-cli-0.0.14 fastapi-cloud-cli-0.3.1 gguf-0.17.1 httptools-0.7.1 interegular-0.3.3 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.11.3 mistral_common-1.8.5 msgspec-0.19.0 ninja-1.13.0 numba-0.61.2 openai-harmony-0.0.4 outlines_core-0.2.11 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.6 pyngrok-7.4.1 ray-2.50.1 rich-toolkit-0.15.1 rignore-0.7.1 setproctitle-1.3.7 setuptools-79.0.1 uvloop-0.22.1 vllm-0.11.0 watchfiles-1.1.1 xformers-0.0.32.post1 xgrammar-0.1.25\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6d08cf3b6af047b593ae72c2e1fba27e",
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install vllm torch pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEWOOOZdwVFf",
        "outputId": "dfbf7e4e-ac1f-4f8a-a831-f247e82cd3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok config add-authtoken YOUR_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "21ebcf507de347c29e90906c45c15ada",
            "6c4979d7ca65461eb7eca4eb488a8b4a",
            "ebc72b3cc8b24ea49343347e5a1470a1",
            "4fb9aa7e934d461ca27d17e4b5957a66",
            "89b52263350949fba500062965415930",
            "13136ba2537140278819825bc851096f",
            "7a51e251a2eb418ca55691c3eb145064",
            "89530df8d4df490a8b4697aae3e9ac1f",
            "54b6e6e9dd6a421797f4394299ed9359",
            "eacce3c626db42c3a734eca9041a1c3e",
            "0cb1f0a2c3074ed3b49669173863e91e",
            "4962839be8694716b76fb62db25cd5a4",
            "3d4cbb7b94ca463983616657ed97edfb",
            "d38fa200fc824c39a6b26bcdfc28743e",
            "67ffa802e2f84b039c6753208354c829",
            "48a44eb3f1744dd7a7a45c95c6daa133",
            "4305909b07e3486fb20e61d1b1cbd8a9",
            "def91e3891cb4fbfbd787ce942aea1fd",
            "c47e9b64fb4543fe81c0873f658c32e8",
            "c7ad1861c09140bbb1cf0e8813b736e7",
            "81414790fbee440899d7546ad873e9ee",
            "b1ff947454694e3e90616eecd11e2a81",
            "4fed7721fb7149f581b7541fc5c9bbc3",
            "87a130b5a6fa4ff9949f6dabe4416494",
            "5f862aff15be4a498e1fc940abbe9300",
            "bbe6597012d945afad7347b9ba85033c",
            "f3ed0bd5bc0f4493b48fae8b7580d515",
            "0f9e32a2a2424b8c828d2fbca80ffaeb",
            "0958981fb55c4f22ab3e6c95b150d488",
            "5ddc1fcf1582479b9af1333b343a05dd",
            "b10d53b6ce274636861d4eec023ef593",
            "27ca299386784598b82d51c62071cd09",
            "035d9167529e4957a1214c331f4ba7cd",
            "291dd1efc1404186ba08d84db19053e8",
            "520a55df250a44a09cb7291805fa5092",
            "0df87cb6227f4c408a3b2aca1a6f2e2f",
            "c1f66bd198e3456c876d25c26115c24f",
            "8dc6ccc0d0254bfd9c3d0f372b34842e",
            "292f007303a84864a404e81a4f6b7cf8",
            "245ccd89ff59408a99317e8156c941c4",
            "38b5738753df4a80b83f78b4e0a00447",
            "1bc5f7bf804648458237fc82bd9609f9",
            "ec24da979bdd4d56b50480168875d4c5",
            "a3b2cb95c9a14e6ba577790db2616c6b",
            "7296f47ddf8047abbef40f516fb49656",
            "6f2e7bc9eca440779df3190946ff50b6",
            "43c9e8f7408c4c27bc5e27b53386c6e7",
            "8714ac68b5f64761b94f083905c2cfaf",
            "fa00e8b2516642dbbf74062972836a78",
            "42693c5abef448f6b42b77d0ff4fb6da",
            "cb8c575af1334815bea9df25ed167e85",
            "3996038136af43a5986f47964104e456",
            "d213996ebd8f4772b553ff00665c8910",
            "4c40c4c2e4c844c39490a7c683176050",
            "355feb2c92284209b4d1181e78c85d69"
          ]
        },
        "id": "pybaIdSPt26N",
        "outputId": "5bc5b312-c8bb-46c2-adce-da3b9de2ce9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 10-25 20:02:31 [__init__.py:216] Automatically detected platform cuda.\n",
            "================================================================================\n",
            "🚀 MODEL YÜKLEME BAŞLIYOR...\n",
            "⏰ Zaman: 20:02:41\n",
            "================================================================================\n",
            "INFO 10-25 20:02:41 [utils.py:233] non-default args: {'trust_remote_code': True, 'dtype': 'float16', 'max_model_len': 4096, 'disable_log_stats': True, 'model': 'ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21ebcf507de347c29e90906c45c15ada",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 10-25 20:02:59 [model.py:547] Resolved architecture: LlamaForCausalLM\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 10-25 20:02:59 [model.py:1733] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 10-25 20:02:59 [model.py:1510] Using max model len 4096\n",
            "INFO 10-25 20:03:03 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4962839be8694716b76fb62db25cd5a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fed7721fb7149f581b7541fc5c9bbc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "291dd1efc1404186ba08d84db19053e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7296f47ddf8047abbef40f516fb49656",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 10-25 20:03:04 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
            "INFO 10-25 20:05:40 [llm.py:306] Supported_tasks: ['generate']\n",
            "✅ Model başarıyla yüklendi!\n",
            "🔧 GPU Kullanımı: %90\n",
            "📏 Max Token: 4096\n",
            "✅ Tokenizer hazır: CachedPreTrainedTokenizerFast\n",
            "\n",
            "================================================================================\n",
            "🌐 NGROK BAŞLATILIYOR...\n",
            "================================================================================\n",
            "\n",
            "✅ API HAZIR!\n",
            "📡 Public URL: NgrokTunnel: \"https://8d284d47fc62.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "\n",
            "🔗 Endpoints:\n",
            "   • Streaming: NgrokTunnel: \"https://8d284d47fc62.ngrok-free.app\" -> \"http://localhost:5000\"/api/generate\n",
            "   • Test: NgrokTunnel: \"https://8d284d47fc62.ngrok-free.app\" -> \"http://localhost:5000\"/api/test\n",
            "   • Health: NgrokTunnel: \"https://8d284d47fc62.ngrok-free.app\" -> \"http://localhost:5000\"/health\n",
            "\n",
            "================================================================================\n",
            "🚀 FLASK SERVER BAŞLATILIYOR...\n",
            "================================================================================\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:06:08\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 448 byte\n",
            "✅ Proje anahtarı: INSIGHT\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1866 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:06:08.611\n",
            "📊 Prompt uzunluğu: 1866 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:06:20] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 3122 karakter\n",
            "📏 Token sayısı: ~409\n",
            "⏱️ Üretim süresi: 12.11 saniye\n",
            "🚀 Hız: 257.9 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**INSIGHT Projesinin Durum Raporu**\n",
            "\n",
            "---\n",
            "\n",
            "**PROJE ÖZET:**\n",
            "Projenizin toplamda 3 görevden oluştuğu görülmektedir. Görevler şu anda üç kişilik ekibiniz tarafından yürütülüyor; Jon (arka uç), Joe (ön uç)...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 6.4% (200/3122)\n",
            "📤 Stream ilerleme: 12.8% (400/3122)\n",
            "📤 Stream ilerleme: 19.2% (600/3122)\n",
            "📤 Stream ilerleme: 25.6% (800/3122)\n",
            "📤 Stream ilerleme: 32.0% (1000/3122)\n",
            "📤 Stream ilerleme: 38.4% (1200/3122)\n",
            "📤 Stream ilerleme: 44.8% (1400/3122)\n",
            "📤 Stream ilerleme: 51.2% (1600/3122)\n",
            "📤 Stream ilerleme: 57.7% (1800/3122)\n",
            "📤 Stream ilerleme: 64.1% (2000/3122)\n",
            "📤 Stream ilerleme: 70.5% (2200/3122)\n",
            "📤 Stream ilerleme: 76.9% (2400/3122)\n",
            "📤 Stream ilerleme: 83.3% (2600/3122)\n",
            "📤 Stream ilerleme: 89.7% (2800/3122)\n",
            "📤 Stream ilerleme: 96.1% (3000/3122)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 3.96 saniye\n",
            "⏱️ Toplam süre: 16.07 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:07:48\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 448 byte\n",
            "✅ Proje anahtarı: INSIGHT\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1866 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:07:48.878\n",
            "📊 Prompt uzunluğu: 1866 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:07:57] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2115 karakter\n",
            "📏 Token sayısı: ~265\n",
            "⏱️ Üretim süresi: 8.46 saniye\n",
            "🚀 Hız: 250.1 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "* **Toplam Görev Sayısı:** Verilen verilerde 3 görev bulunmaktadır.\n",
            "* **Durum Dağılımı:**\n",
            "\t+ İn Progress (2): Backend API geliştirmede Jon ile Frontend UI'deki Joe çalışmaktadır.\n",
            "\t+ ...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 9.5% (200/2115)\n",
            "📤 Stream ilerleme: 18.9% (400/2115)\n",
            "📤 Stream ilerleme: 28.4% (600/2115)\n",
            "📤 Stream ilerleme: 37.8% (800/2115)\n",
            "📤 Stream ilerleme: 47.3% (1000/2115)\n",
            "📤 Stream ilerleme: 56.7% (1200/2115)\n",
            "📤 Stream ilerleme: 66.2% (1400/2115)\n",
            "📤 Stream ilerleme: 75.7% (1600/2115)\n",
            "📤 Stream ilerleme: 85.1% (1800/2115)\n",
            "📤 Stream ilerleme: 94.6% (2000/2115)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 2.69 saniye\n",
            "⏱️ Toplam süre: 11.14 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:09:33\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 448 byte\n",
            "✅ Proje anahtarı: INSIGHT\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1866 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:09:33.746\n",
            "📊 Prompt uzunluğu: 1866 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:09:44] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2910 karakter\n",
            "📏 Token sayısı: ~357\n",
            "⏱️ Üretim süresi: 10.91 saniye\n",
            "🚀 Hız: 266.7 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "* **Toplam Görev Sayısı:** 3 görev\n",
            "* **Durum Dağılımı:** \n",
            "\t+ In Progress (2): Backend API geliştirme ve Frontend UI\n",
            "\t+ Completed (1): Design mockupları\n",
            "* **Tamamlanma Yüzdesi:** %33 ...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 6.9% (200/2910)\n",
            "📤 Stream ilerleme: 13.7% (400/2910)\n",
            "📤 Stream ilerleme: 20.6% (600/2910)\n",
            "📤 Stream ilerleme: 27.5% (800/2910)\n",
            "📤 Stream ilerleme: 34.4% (1000/2910)\n",
            "📤 Stream ilerleme: 41.2% (1200/2910)\n",
            "📤 Stream ilerleme: 48.1% (1400/2910)\n",
            "📤 Stream ilerleme: 55.0% (1600/2910)\n",
            "📤 Stream ilerleme: 61.9% (1800/2910)\n",
            "📤 Stream ilerleme: 68.7% (2000/2910)\n",
            "📤 Stream ilerleme: 75.6% (2200/2910)\n",
            "📤 Stream ilerleme: 82.5% (2400/2910)\n",
            "📤 Stream ilerleme: 89.3% (2600/2910)\n",
            "📤 Stream ilerleme: 96.2% (2800/2910)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 3.69 saniye\n",
            "⏱️ Toplam süre: 14.60 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:18:13] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:39:29] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:39:30] \"\u001b[31m\u001b[1mPOST /api/generate HTTP/1.1\u001b[0m\" 400 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:39:30\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "❌ JSON girdisi bulunamadı!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:39:44] \"\u001b[31m\u001b[1mGET /api/generate HTTP/1.1\u001b[0m\" 405 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:40:07\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 448 byte\n",
            "✅ Proje anahtarı: INSIGHT\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1866 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:40:07.460\n",
            "📊 Prompt uzunluğu: 1866 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:40:13] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:40:16] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2118 karakter\n",
            "📏 Token sayısı: ~270\n",
            "⏱️ Üretim süresi: 8.80 saniye\n",
            "🚀 Hız: 240.6 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**PROJE ÖZET:**\n",
            "\n",
            "* **Proje Adı:** AI Güdümlü Öğrenme Aracı (AI Powered Learning Tool)\n",
            "* **Tür:** Eğitim Araçları\n",
            "* **Hedef:** Çocukların kodlamayı öğrenmesine yardımcı olmak için geliştirdiğimiz bir a...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 9.4% (200/2118)\n",
            "📤 Stream ilerleme: 18.9% (400/2118)\n",
            "📤 Stream ilerleme: 28.3% (600/2118)\n",
            "📤 Stream ilerleme: 37.8% (800/2118)\n",
            "📤 Stream ilerleme: 47.2% (1000/2118)\n",
            "📤 Stream ilerleme: 56.7% (1200/2118)\n",
            "📤 Stream ilerleme: 66.1% (1400/2118)\n",
            "📤 Stream ilerleme: 75.5% (1600/2118)\n",
            "📤 Stream ilerleme: 85.0% (1800/2118)\n",
            "📤 Stream ilerleme: 94.4% (2000/2118)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 2.69 saniye\n",
            "⏱️ Toplam süre: 11.49 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:40:20] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:42:31] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:43:11] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:44:33\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 498 byte\n",
            "✅ Proje anahtarı: p02\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1928 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:44:33.807\n",
            "📊 Prompt uzunluğu: 1928 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:44:43] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2727 karakter\n",
            "📏 Token sayısı: ~330\n",
            "⏱️ Üretim süresi: 9.84 saniye\n",
            "🚀 Hız: 277.0 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "Bu raporda, build edilen mobil uygulamanın iOS ve Android platformları için (proje_description) incelenmektedir. Şu anda iki ekip üyesinin olduğu takım bilgisi verilmemektedir. Görev...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 7.3% (200/2727)\n",
            "📤 Stream ilerleme: 14.7% (400/2727)\n",
            "📤 Stream ilerleme: 22.0% (600/2727)\n",
            "📤 Stream ilerleme: 29.3% (800/2727)\n",
            "📤 Stream ilerleme: 36.7% (1000/2727)\n",
            "📤 Stream ilerleme: 44.0% (1200/2727)\n",
            "📤 Stream ilerleme: 51.3% (1400/2727)\n",
            "📤 Stream ilerleme: 58.7% (1600/2727)\n",
            "📤 Stream ilerleme: 66.0% (1800/2727)\n",
            "📤 Stream ilerleme: 73.3% (2000/2727)\n",
            "📤 Stream ilerleme: 80.7% (2200/2727)\n",
            "📤 Stream ilerleme: 88.0% (2400/2727)\n",
            "📤 Stream ilerleme: 95.3% (2600/2727)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 3.46 saniye\n",
            "⏱️ Toplam süre: 13.30 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:45:03\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 498 byte\n",
            "✅ Proje anahtarı: p02\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1928 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:45:03.625\n",
            "📊 Prompt uzunluğu: 1928 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:45:11] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2102 karakter\n",
            "📏 Token sayısı: ~257\n",
            "⏱️ Üretim süresi: 7.97 saniye\n",
            "🚀 Hız: 263.8 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "* **Toplam Görev Sayısı:** 4 görev bulunmaktadır.\n",
            "* **Durum Dağılımı:**\n",
            "\t+ Pending Durumu: 2 (50%)\n",
            "\t+ Completed Durumu: 2 (50%)\n",
            "\n",
            "Tamamlama Yüzdesi: %100 (%)\n",
            "\n",
            "---\n",
            "\n",
            "**Riskler ve Dikkat...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 9.5% (200/2102)\n",
            "📤 Stream ilerleme: 19.0% (400/2102)\n",
            "📤 Stream ilerleme: 28.5% (600/2102)\n",
            "📤 Stream ilerleme: 38.1% (800/2102)\n",
            "📤 Stream ilerleme: 47.6% (1000/2102)\n",
            "📤 Stream ilerleme: 57.1% (1200/2102)\n",
            "📤 Stream ilerleme: 66.6% (1400/2102)\n",
            "📤 Stream ilerleme: 76.1% (1600/2102)\n",
            "📤 Stream ilerleme: 85.6% (1800/2102)\n",
            "📤 Stream ilerleme: 95.1% (2000/2102)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 2.67 saniye\n",
            "⏱️ Toplam süre: 10.63 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:45:59\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 498 byte\n",
            "✅ Proje anahtarı: p02\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1928 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:45:59.093\n",
            "📊 Prompt uzunluğu: 1928 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:46:09] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2614 karakter\n",
            "📏 Token sayısı: ~323\n",
            "⏱️ Üretim süresi: 9.97 saniye\n",
            "🚀 Hız: 262.3 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**PROJE ÖZET:**\n",
            "\n",
            "* **Toplam Görev Sayısı:** 4 görev bulunmaktadır.\n",
            "* **Durum Dağılımı:** Tamamlanan görevler %50 (%2) ile birlikte toplamda %75'e tekabül ederken, kalan görevler %25'ini oluşturmaktadı...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:46:18\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 498 byte\n",
            "✅ Proje anahtarı: p02\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1928 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:46:18.341\n",
            "📊 Prompt uzunluğu: 1928 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:46:28] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2749 karakter\n",
            "📏 Token sayısı: ~325\n",
            "⏱️ Üretim süresi: 10.35 saniye\n",
            "🚀 Hız: 265.5 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**PROJE ÖZET:**\n",
            "\n",
            "Proje açıklamasına göre, bu proje mobil uygulamanın hem iOS hem de Android platformları için geliştirilmesi ile ilgilidir. Verilen bilgilerden yola çıkarak aşağıdaki sonuçlara varabil...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 7.3% (200/2749)\n",
            "📤 Stream ilerleme: 14.6% (400/2749)\n",
            "📤 Stream ilerleme: 21.8% (600/2749)\n",
            "📤 Stream ilerleme: 29.1% (800/2749)\n",
            "📤 Stream ilerleme: 36.4% (1000/2749)\n",
            "📤 Stream ilerleme: 43.7% (1200/2749)\n",
            "📤 Stream ilerleme: 50.9% (1400/2749)\n",
            "📤 Stream ilerleme: 58.2% (1600/2749)\n",
            "📤 Stream ilerleme: 65.5% (1800/2749)\n",
            "📤 Stream ilerleme: 72.8% (2000/2749)\n",
            "📤 Stream ilerleme: 80.0% (2200/2749)\n",
            "📤 Stream ilerleme: 87.3% (2400/2749)\n",
            "📤 Stream ilerleme: 94.6% (2600/2749)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 3.49 saniye\n",
            "⏱️ Toplam süre: 13.84 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:46:59\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 498 byte\n",
            "✅ Proje anahtarı: p02\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1928 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:46:59.018\n",
            "📊 Prompt uzunluğu: 1928 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:47:06] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2170 karakter\n",
            "📏 Token sayısı: ~270\n",
            "⏱️ Üretim süresi: 7.88 saniye\n",
            "🚀 Hız: 275.4 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "**Toplam Görev Sayısı:** 4 adet\n",
            "\n",
            "**Durum Dağılımı:**\n",
            "- Tamamlandı: 1 (25%)\n",
            "- Bekleyen: 3 (75%)\n",
            "\n",
            "**Tamamlama Yüzdesi:** %25\n",
            "\n",
            "---\n",
            "\n",
            "**Riskler ve Dikkate Alınacak Hususlar:**\n",
            "\n",
            "* **Kritik...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 9.2% (200/2170)\n",
            "📤 Stream ilerleme: 18.4% (400/2170)\n",
            "📤 Stream ilerleme: 27.6% (600/2170)\n",
            "📤 Stream ilerleme: 36.9% (800/2170)\n",
            "📤 Stream ilerleme: 46.1% (1000/2170)\n",
            "📤 Stream ilerleme: 55.3% (1200/2170)\n",
            "📤 Stream ilerleme: 64.5% (1400/2170)\n",
            "📤 Stream ilerleme: 73.7% (1600/2170)\n",
            "📤 Stream ilerleme: 82.9% (1800/2170)\n",
            "📤 Stream ilerleme: 92.2% (2000/2170)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 2.76 saniye\n",
            "⏱️ Toplam süre: 10.64 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:53:59\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 498 byte\n",
            "✅ Proje anahtarı: p02\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 1928 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:53:59.188\n",
            "📊 Prompt uzunluğu: 1928 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:54:10] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2931 karakter\n",
            "📏 Token sayısı: ~374\n",
            "⏱️ Üretim süresi: 10.90 saniye\n",
            "🚀 Hız: 268.8 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "Bu raporda \"iOS ve Android mobil uygulamasının geliştirilmesi\" olan p02 adlı bir proje incelenecektir. Aşağıda proje özetinin ve ilgili ayrıntıların yer aldığı bir tablo bulunmaktadı...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 6.8% (200/2931)\n",
            "📤 Stream ilerleme: 13.6% (400/2931)\n",
            "📤 Stream ilerleme: 20.5% (600/2931)\n",
            "📤 Stream ilerleme: 27.3% (800/2931)\n",
            "📤 Stream ilerleme: 34.1% (1000/2931)\n",
            "📤 Stream ilerleme: 40.9% (1200/2931)\n",
            "📤 Stream ilerleme: 47.8% (1400/2931)\n",
            "📤 Stream ilerleme: 54.6% (1600/2931)\n",
            "📤 Stream ilerleme: 61.4% (1800/2931)\n",
            "📤 Stream ilerleme: 68.2% (2000/2931)\n",
            "📤 Stream ilerleme: 75.1% (2200/2931)\n",
            "📤 Stream ilerleme: 81.9% (2400/2931)\n",
            "📤 Stream ilerleme: 88.7% (2600/2931)\n",
            "📤 Stream ilerleme: 95.5% (2800/2931)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 3.72 saniye\n",
            "⏱️ Toplam süre: 14.63 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:55:30\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 647 byte\n",
            "✅ Proje anahtarı: p987\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 2105 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:55:30.614\n",
            "📊 Prompt uzunluğu: 2105 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:55:38] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 1965 karakter\n",
            "📏 Token sayısı: ~243\n",
            "⏱️ Üretim süresi: 7.78 saniye\n",
            "🚀 Hız: 252.5 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "Proje Adı: Planlama Uygulaması\n",
            "\n",
            "Toplam Görev Sayısı: 5\n",
            "\n",
            "Durum Dağılımı:\n",
            "\n",
            "* Bekleyen görevler: %100 (Beş görevin tamamında status 'Bekleniyor')\n",
            "\n",
            "Tamamlanma Yüzdesi: %0\n",
            "\n",
            "**Riskler ve D...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 10.2% (200/1965)\n",
            "📤 Stream ilerleme: 20.4% (400/1965)\n",
            "📤 Stream ilerleme: 30.5% (600/1965)\n",
            "📤 Stream ilerleme: 40.7% (800/1965)\n",
            "📤 Stream ilerleme: 50.9% (1000/1965)\n",
            "📤 Stream ilerleme: 61.1% (1200/1965)\n",
            "📤 Stream ilerleme: 71.2% (1400/1965)\n",
            "📤 Stream ilerleme: 81.4% (1600/1965)\n",
            "📤 Stream ilerleme: 91.6% (1800/1965)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 2.49 saniye\n",
            "⏱️ Toplam süre: 10.27 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:55:56\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 647 byte\n",
            "✅ Proje anahtarı: p987\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 2105 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:55:56.492\n",
            "📊 Prompt uzunluğu: 2105 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:55:59\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 647 byte\n",
            "✅ Proje anahtarı: p987\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 2105 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:55:59.000\n",
            "📊 Prompt uzunluğu: 2105 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:56:00\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 647 byte\n",
            "✅ Proje anahtarı: p987\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 2105 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:56:00.701\n",
            "📊 Prompt uzunluğu: 2105 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:56:09] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2170 karakter\n",
            "📏 Token sayısı: ~277\n",
            "⏱️ Üretim süresi: 13.34 saniye\n",
            "🚀 Hız: 162.7 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "Verilen P987 projesinin toplamda 5 görevi bulunmaktadır. Görevlerin tamamında da \"Bekleme\" (Pending) olarak durumdadır. Bu nedenle proje genelinde %0 tamamlanma oranına sahip olduğun...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:56:47\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 647 byte\n",
            "✅ Proje anahtarı: p987\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 2105 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:56:47.383\n",
            "📊 Prompt uzunluğu: 2105 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:56:49\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 647 byte\n",
            "✅ Proje anahtarı: p987\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 2105 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:56:49.442\n",
            "📊 Prompt uzunluğu: 2105 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:56:59] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 3092 karakter\n",
            "📏 Token sayısı: ~385\n",
            "⏱️ Üretim süresi: 9.79 saniye\n",
            "🚀 Hız: 315.9 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**PROJE RAPORU:**\n",
            "\n",
            "**Proje Özeti:**\n",
            "Projenin adı \"Planlama Uygulaması\" olup, planlama uygulamanızın tasarımı, geliştirilmesi, test edilmesi ve dağıtılmasını içermektedir. Şu anda toplamda 5 görev bulu...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "📤 Stream ilerleme: 6.5% (200/3092)\n",
            "📤 Stream ilerleme: 12.9% (400/3092)\n",
            "📤 Stream ilerleme: 19.4% (600/3092)\n",
            "📤 Stream ilerleme: 25.9% (800/3092)\n",
            "📤 Stream ilerleme: 32.3% (1000/3092)\n",
            "📤 Stream ilerleme: 38.8% (1200/3092)\n",
            "📤 Stream ilerleme: 45.3% (1400/3092)\n",
            "📤 Stream ilerleme: 51.7% (1600/3092)\n",
            "📤 Stream ilerleme: 58.2% (1800/3092)\n",
            "📤 Stream ilerleme: 64.7% (2000/3092)\n",
            "📤 Stream ilerleme: 71.2% (2200/3092)\n",
            "📤 Stream ilerleme: 77.6% (2400/3092)\n",
            "📤 Stream ilerleme: 84.1% (2600/3092)\n",
            "📤 Stream ilerleme: 90.6% (2800/3092)\n",
            "📤 Stream ilerleme: 97.0% (3000/3092)\n",
            "\n",
            "✅ STREAMING TAMAMLANDI!\n",
            "⏱️ Stream süresi: 3.92 saniye\n",
            "⏱️ Toplam süre: 13.71 saniye\n",
            "================================================================================\n",
            "\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "📥 YENİ STREAMING İSTEK GELDİ\n",
            "⏰ Zaman: 20:58:01\n",
            "================================================================================\n",
            "🔍 Veri doğrulanıyor...\n",
            "✅ JSON verisi alındı - Boyut: 647 byte\n",
            "✅ Proje anahtarı: p987\n",
            "✅ Veri tipi: <class 'dict'>\n",
            "📝 Prompt oluşturuluyor...\n",
            "✅ Chat template uygulandı\n",
            "✅ Prompt hazır - Uzunluk: 2105 karakter\n",
            "🚀 Streaming response başlatılıyor...\n",
            "\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "🤖 MODEL ÇALIŞIYOR...\n",
            "⏰ Başlangıç: 20:58:01.570\n",
            "📊 Prompt uzunluğu: 2105 karakter\n",
            "🎚️ Temperature: 0.7\n",
            "🎯 Max tokens: 2048\n",
            "🛑 Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:58:10] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🏁 Finish Reason: stop\n",
            "\n",
            "✅ MODEL ÇIKTI ÜRETTİ!\n",
            "📏 Çıktı uzunluğu: 2683 karakter\n",
            "📏 Token sayısı: ~318\n",
            "⏱️ Üretim süresi: 129.33 saniye\n",
            "🚀 Hız: 20.7 karakter/saniye\n",
            "\n",
            "📖 Önizleme:\n",
            "**Proje Özeti:**\n",
            "\n",
            "p987 Projesinin özetini inceleyerek toplamda beş adet göreve sahip olduğunu görüyoruz. Görevlerin tamamına bakarak bu projede hala planlama uygulamasının oluşturma sürecinde olduğumu...\n",
            "🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄🔄\n",
            "\n",
            "📡 STREAMING BAŞLIYOR...\n",
            "🧹 Bellek temizliği yapılıyor...\n",
            "✅ Bellek temizlendi\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from flask import Flask, request, jsonify, Response, stream_with_context\n",
        "from vllm import LLM, SamplingParams\n",
        "import json\n",
        "import gc\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL YÜKLEME\n",
        "# ============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"🚀 MODEL YÜKLEME BAŞLIYOR...\")\n",
        "print(f\"⏰ Zaman: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    llm_planner = LLM(\n",
        "        model=\"ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1\",\n",
        "        trust_remote_code=True,\n",
        "        gpu_memory_utilization=0.90,\n",
        "        max_model_len=4096,\n",
        "        dtype=\"float16\"\n",
        "    )\n",
        "    print(\"✅ Model başarıyla yüklendi!\")\n",
        "    print(f\"🔧 GPU Kullanımı: %90\")\n",
        "    print(f\"📏 Max Token: 4096\")\n",
        "\n",
        "    # Tokenizer'ı al (chat template için)\n",
        "    tokenizer = llm_planner.get_tokenizer()\n",
        "    print(f\"✅ Tokenizer hazır: {tokenizer.__class__.__name__}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Model yükleme hatası: {e}\")\n",
        "    raise\n",
        "\n",
        "# ============================================================================\n",
        "# SİSTEM PROMPTU\n",
        "# ============================================================================\n",
        "SYSTEM_PROMPT = \"\"\"Sen uzman bir proje analiz asistanısın. Görüvin Jira verilerini analiz edip projenin mevcut durumu hakkında detaylı, yapıcı ve net değerlendirmeler yapmak.\n",
        "\n",
        "GÖREV TANIMLARIN:\n",
        "1. Proje Sağlığı Değerlendirmesi - Issue durumlarını analiz et\n",
        "2. Risk Tespiti - Gecikmeler, bloke durumlar, atanmamış işleri belirle\n",
        "3. Sprint Performansı - İlerlemeyi ve hedeflere ulaşmayı değerlendir\n",
        "4. Kaynak Dağılımı - Ekip iş yükü dağılımını incele\n",
        "5. Öncelik Analizi - Yüksek öncelikli görevleri kontrol et\n",
        "\n",
        "ÇIKTI FORMATI:\n",
        "\n",
        "PROJE ÖZET:\n",
        "- Toplam görev sayısı ve durum dağılımı\n",
        "- Tamamlanma yüzdesi\n",
        "\n",
        "RİSKLER VE DİKKAT GEREKENLER:\n",
        "- Kritik riskler\n",
        "- Gecikmeler\n",
        "- Bloke durumlar\n",
        "\n",
        "ÖNCELİK DURUMU:\n",
        "- Yüksek öncelikli görevlerin durumu\n",
        "- Acil müdahale gereken konular\n",
        "\n",
        "EKİP PERFORMANSI:\n",
        "- İş yükü dağılımı\n",
        "- Atanmamış görevler\n",
        "\n",
        "ÖNERİLER:\n",
        "- Kısa vadeli aksiyon önerileri\n",
        "- Süreç iyileştirme önerileri\n",
        "\n",
        "Net, anlaşılır ve Türkçe yaz. Rakamlarla destekle.\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# YARDIMCI FONKSİYONLAR\n",
        "# ============================================================================\n",
        "def format_chat_prompt(system_msg: str, user_msg: str) -> str:\n",
        "    \"\"\"Chat template ile prompt formatla\"\"\"\n",
        "    try:\n",
        "        # Llama chat format\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\", \"content\": user_msg}\n",
        "        ]\n",
        "\n",
        "        # Tokenizer'ın chat template'i varsa kullan\n",
        "        if hasattr(tokenizer, 'apply_chat_template'):\n",
        "            formatted = tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "            print(\"✅ Chat template uygulandı\")\n",
        "            return formatted\n",
        "        else:\n",
        "            # Manuel format (Llama style)\n",
        "            formatted = f\"<s>[INST] <<SYS>>\\n{system_msg}\\n<</SYS>>\\n\\n{user_msg} [/INST]\"\n",
        "            print(\"✅ Manuel Llama format uygulandı\")\n",
        "            return formatted\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Chat template hatası: {e}\")\n",
        "        # Fallback: basit format\n",
        "        return f\"{system_msg}\\n\\n{user_msg}\\n\\nYanıt:\"\n",
        "\n",
        "def create_analysis_prompt(json_data: dict, project_key: str) -> str:\n",
        "    \"\"\"JSON verisini analiz için prompt haline getirir\"\"\"\n",
        "    try:\n",
        "        print(f\"📝 Prompt oluşturuluyor...\")\n",
        "        json_str = json.dumps(json_data, indent=2, ensure_ascii=False)\n",
        "\n",
        "        user_message = f\"\"\"Aşağıdaki {project_key} projesi verilerini analiz et ve belirlenen formatta detaylı bir rapor hazırla.\n",
        "\n",
        "PROJE VERİLERİ:\n",
        "{json_str}\n",
        "\n",
        "Lütfen yukarıdaki verileri dikkatlice analiz edip tam ve detaylı bir rapor oluştur. Her başlık altında somut bulgular ve öneriler sun.\"\"\"\n",
        "\n",
        "        prompt = format_chat_prompt(SYSTEM_PROMPT, user_message)\n",
        "\n",
        "        print(f\"✅ Prompt hazır - Uzunluk: {len(prompt)} karakter\")\n",
        "        return prompt\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Prompt oluşturma hatası: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "def generate_streaming_response(prompt: str):\n",
        "    \"\"\"vLLM ile streaming text üretir\"\"\"\n",
        "\n",
        "    # DÜZELTİLMİŞ SAMPLING PARAMETRELERİ\n",
        "    sampling_params = SamplingParams(\n",
        "        temperature=0.7,           # Biraz daha yaratıcı\n",
        "        top_p=0.95,\n",
        "        top_k=50,\n",
        "        max_tokens=2048,           # Daha uzun çıktı için\n",
        "        repetition_penalty=1.15,   # Tekrarı azalt\n",
        "        presence_penalty=0.1,      # Çeşitliliği artır\n",
        "        frequency_penalty=0.1,\n",
        "        stop=None,                 # Stop token'ları kaldır!\n",
        "        skip_special_tokens=True   # Özel token'ları atla\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(\"\\n\" + \"🔄\" * 40)\n",
        "        print(f\"🤖 MODEL ÇALIŞIYOR...\")\n",
        "        print(f\"⏰ Başlangıç: {datetime.now().strftime('%H:%M:%S.%f')[:-3]}\")\n",
        "        print(f\"📊 Prompt uzunluğu: {len(prompt)} karakter\")\n",
        "        print(f\"🎚️ Temperature: {sampling_params.temperature}\")\n",
        "        print(f\"🎯 Max tokens: {sampling_params.max_tokens}\")\n",
        "        print(f\"🛑 Stop tokens: {sampling_params.stop}\")\n",
        "\n",
        "        # Model üretimi\n",
        "        start_time = time.time()\n",
        "        outputs = llm_planner.generate([prompt], sampling_params, use_tqdm=False)\n",
        "        generation_time = time.time() - start_time\n",
        "\n",
        "        full_text = outputs[0].outputs[0].text.strip()\n",
        "\n",
        "        # Debug: finish reason kontrol et\n",
        "        finish_reason = outputs[0].outputs[0].finish_reason\n",
        "        print(f\"\\n🏁 Finish Reason: {finish_reason}\")\n",
        "\n",
        "        print(f\"\\n✅ MODEL ÇIKTI ÜRETTİ!\")\n",
        "        print(f\"📏 Çıktı uzunluğu: {len(full_text)} karakter\")\n",
        "        print(f\"📏 Token sayısı: ~{len(full_text.split())}\")\n",
        "        print(f\"⏱️ Üretim süresi: {generation_time:.2f} saniye\")\n",
        "        print(f\"🚀 Hız: {len(full_text)/generation_time:.1f} karakter/saniye\")\n",
        "\n",
        "        # İlk 200 karakteri göster\n",
        "        preview = full_text[:200] + \"...\" if len(full_text) > 200 else full_text\n",
        "        print(f\"\\n📖 Önizleme:\\n{preview}\")\n",
        "        print(\"🔄\" * 40 + \"\\n\")\n",
        "\n",
        "        # Streaming başlangıcı\n",
        "        print(\"📡 STREAMING BAŞLIYOR...\")\n",
        "        stream_start = time.time()\n",
        "\n",
        "        # Metni chunk'lar halinde stream et\n",
        "        chunk_size = 8  # Her seferde 8 karakter\n",
        "        for i in range(0, len(full_text), chunk_size):\n",
        "            chunk = full_text[i:i+chunk_size]\n",
        "            yield f\"data: {json.dumps({'text': chunk, 'done': False}, ensure_ascii=False)}\\n\\n\"\n",
        "\n",
        "            # Her 200 karakterde bir durum raporu\n",
        "            if i % 200 == 0 and i > 0:\n",
        "                progress = (i / len(full_text)) * 100\n",
        "                print(f\"📤 Stream ilerleme: {progress:.1f}% ({i}/{len(full_text)})\")\n",
        "\n",
        "            time.sleep(0.01)  # Smooth streaming\n",
        "\n",
        "        stream_time = time.time() - stream_start\n",
        "\n",
        "        # Tamamlandı sinyali\n",
        "        yield f\"data: {json.dumps({'text': '', 'done': True})}\\n\\n\"\n",
        "\n",
        "        print(f\"\\n✅ STREAMING TAMAMLANDI!\")\n",
        "        print(f\"⏱️ Stream süresi: {stream_time:.2f} saniye\")\n",
        "        print(f\"⏱️ Toplam süre: {(generation_time + stream_time):.2f} saniye\")\n",
        "        print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Üretim hatası: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        yield f\"data: {json.dumps({'error': error_msg, 'done': True})}\\n\\n\"\n",
        "\n",
        "    finally:\n",
        "        # Bellek temizliği\n",
        "        print(\"🧹 Bellek temizliği yapılıyor...\")\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(\"✅ Bellek temizlendi\")\n",
        "\n",
        "# ============================================================================\n",
        "# FLASK UYGULAMASI\n",
        "# ============================================================================\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/api/generate', methods=['POST'])\n",
        "def generate():\n",
        "    \"\"\"Streaming proje analizi endpoint'i\"\"\"\n",
        "    request_time = datetime.now()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"📥 YENİ STREAMING İSTEK GELDİ\")\n",
        "    print(f\"⏰ Zaman: {request_time.strftime('%H:%M:%S')}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    try:\n",
        "        # Veri doğrulama\n",
        "        print(\"🔍 Veri doğrulanıyor...\")\n",
        "        data = request.get_json()\n",
        "\n",
        "        if not data:\n",
        "            print(\"❌ JSON girdisi bulunamadı!\")\n",
        "            return jsonify({\"error\": \"JSON girdisi bulunamadı\"}), 400\n",
        "\n",
        "        print(f\"✅ JSON verisi alındı - Boyut: {len(str(data))} byte\")\n",
        "\n",
        "        json_input = data.get(\"json_input\")\n",
        "        project_key = data.get(\"project_key\", \"PROJECT\")\n",
        "\n",
        "        if not json_input:\n",
        "            print(\"❌ json_input alanı eksik!\")\n",
        "            return jsonify({\"error\": \"json_input alanı gerekli\"}), 400\n",
        "\n",
        "        print(f\"✅ Proje anahtarı: {project_key}\")\n",
        "        print(f\"✅ Veri tipi: {type(json_input)}\")\n",
        "\n",
        "        # Eğer string ise parse et\n",
        "        if isinstance(json_input, str):\n",
        "            try:\n",
        "                json_input = json.loads(json_input)\n",
        "                print(\"✅ JSON string parse edildi\")\n",
        "            except:\n",
        "                print(\"⚠️ JSON parse edilemedi, string olarak devam ediliyor\")\n",
        "\n",
        "        # Prompt oluştur\n",
        "        prompt = create_analysis_prompt(json_input, project_key)\n",
        "\n",
        "        if prompt.startswith(\"❌\"):\n",
        "            return jsonify({\"error\": prompt}), 400\n",
        "\n",
        "        # Streaming response döndür\n",
        "        print(\"🚀 Streaming response başlatılıyor...\")\n",
        "        return Response(\n",
        "            stream_with_context(generate_streaming_response(prompt)),\n",
        "            mimetype='text/event-stream',\n",
        "            headers={\n",
        "                'Cache-Control': 'no-cache',\n",
        "                'X-Accel-Buffering': 'no',\n",
        "                'Connection': 'keep-alive',\n",
        "                'Access-Control-Allow-Origin': '*'\n",
        "            }\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ HATA OLUŞTU!\")\n",
        "        print(f\"Hata mesajı: {str(e)}\")\n",
        "        import traceback\n",
        "        print(\"\\n📋 Stack trace:\")\n",
        "        traceback.print_exc()\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    \"\"\"Health check endpoint'i\"\"\"\n",
        "    print(f\"💚 Health check - {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "    try:\n",
        "        gpu_available = torch.cuda.is_available()\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3 if gpu_available else 0\n",
        "\n",
        "        return jsonify({\n",
        "            \"status\": \"healthy\",\n",
        "            \"model\": \"ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1\",\n",
        "            \"gpu_available\": gpu_available,\n",
        "            \"gpu_memory_gb\": round(gpu_memory, 2),\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }), 200\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Health check hatası: {e}\")\n",
        "        return jsonify({\"status\": \"unhealthy\", \"error\": str(e)}), 500\n",
        "\n",
        "# ============================================================================\n",
        "# TEST ENDPOINTİ (Debug için)\n",
        "# ============================================================================\n",
        "@app.route('/api/test', methods=['GET'])\n",
        "def test():\n",
        "    \"\"\"Basit test endpoint'i\"\"\"\n",
        "    print(\"🧪 Test endpoint çağrıldı\")\n",
        "\n",
        "    test_data = {\n",
        "        \"issues\": [\n",
        "            {\"key\": \"TEST-1\", \"status\": \"Done\", \"priority\": \"High\"},\n",
        "            {\"key\": \"TEST-2\", \"status\": \"In Progress\", \"priority\": \"Medium\"},\n",
        "            {\"key\": \"TEST-3\", \"status\": \"To Do\", \"priority\": \"Low\"}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    prompt = create_analysis_prompt(test_data, \"TEST\")\n",
        "\n",
        "    return Response(\n",
        "        stream_with_context(generate_streaming_response(prompt)),\n",
        "        mimetype='text/event-stream',\n",
        "        headers={'Cache-Control': 'no-cache', 'X-Accel-Buffering': 'no'}\n",
        "    )\n",
        "\n",
        "# ============================================================================\n",
        "# NGROK SETUP\n",
        "# ============================================================================\n",
        "try:\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"🌐 NGROK BAŞLATILIYOR...\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    ngrok.kill()\n",
        "\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"\\n✅ API HAZIR!\")\n",
        "    print(f\"📡 Public URL: {public_url}\")\n",
        "    print(f\"\\n🔗 Endpoints:\")\n",
        "    print(f\"   • Streaming: {public_url}/api/generate\")\n",
        "    print(f\"   • Test: {public_url}/api/test\")\n",
        "    print(f\"   • Health: {public_url}/health\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"\\n⚠️ pyngrok yüklü değil. Local olarak çalışılıyor.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Ngrok hatası: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SERVER BAŞLATMA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"🚀 FLASK SERVER BAŞLATILIYOR...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000, threaded=True, debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdgEK3g-wttE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "035d9167529e4957a1214c331f4ba7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0958981fb55c4f22ab3e6c95b150d488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cb1f0a2c3074ed3b49669173863e91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0df87cb6227f4c408a3b2aca1a6f2e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38b5738753df4a80b83f78b4e0a00447",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bc5f7bf804648458237fc82bd9609f9",
            "value": 296
          }
        },
        "0f9e32a2a2424b8c828d2fbca80ffaeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13136ba2537140278819825bc851096f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc5f7bf804648458237fc82bd9609f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21ebcf507de347c29e90906c45c15ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c4979d7ca65461eb7eca4eb488a8b4a",
              "IPY_MODEL_ebc72b3cc8b24ea49343347e5a1470a1",
              "IPY_MODEL_4fb9aa7e934d461ca27d17e4b5957a66"
            ],
            "layout": "IPY_MODEL_89b52263350949fba500062965415930"
          }
        },
        "245ccd89ff59408a99317e8156c941c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27ca299386784598b82d51c62071cd09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "291dd1efc1404186ba08d84db19053e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_520a55df250a44a09cb7291805fa5092",
              "IPY_MODEL_0df87cb6227f4c408a3b2aca1a6f2e2f",
              "IPY_MODEL_c1f66bd198e3456c876d25c26115c24f"
            ],
            "layout": "IPY_MODEL_8dc6ccc0d0254bfd9c3d0f372b34842e"
          }
        },
        "292f007303a84864a404e81a4f6b7cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355feb2c92284209b4d1181e78c85d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38b5738753df4a80b83f78b4e0a00447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3996038136af43a5986f47964104e456": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4cbb7b94ca463983616657ed97edfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4305909b07e3486fb20e61d1b1cbd8a9",
            "placeholder": "​",
            "style": "IPY_MODEL_def91e3891cb4fbfbd787ce942aea1fd",
            "value": "tokenizer_config.json: "
          }
        },
        "42693c5abef448f6b42b77d0ff4fb6da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4305909b07e3486fb20e61d1b1cbd8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c9e8f7408c4c27bc5e27b53386c6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3996038136af43a5986f47964104e456",
            "max": 172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d213996ebd8f4772b553ff00665c8910",
            "value": 172
          }
        },
        "48a44eb3f1744dd7a7a45c95c6daa133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4962839be8694716b76fb62db25cd5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d4cbb7b94ca463983616657ed97edfb",
              "IPY_MODEL_d38fa200fc824c39a6b26bcdfc28743e",
              "IPY_MODEL_67ffa802e2f84b039c6753208354c829"
            ],
            "layout": "IPY_MODEL_48a44eb3f1744dd7a7a45c95c6daa133"
          }
        },
        "4c40c4c2e4c844c39490a7c683176050": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb9aa7e934d461ca27d17e4b5957a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eacce3c626db42c3a734eca9041a1c3e",
            "placeholder": "​",
            "style": "IPY_MODEL_0cb1f0a2c3074ed3b49669173863e91e",
            "value": " 727/727 [00:00&lt;00:00, 97.6kB/s]"
          }
        },
        "4fed7721fb7149f581b7541fc5c9bbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87a130b5a6fa4ff9949f6dabe4416494",
              "IPY_MODEL_5f862aff15be4a498e1fc940abbe9300",
              "IPY_MODEL_bbe6597012d945afad7347b9ba85033c"
            ],
            "layout": "IPY_MODEL_f3ed0bd5bc0f4493b48fae8b7580d515"
          }
        },
        "520a55df250a44a09cb7291805fa5092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_292f007303a84864a404e81a4f6b7cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_245ccd89ff59408a99317e8156c941c4",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "54b6e6e9dd6a421797f4394299ed9359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ddc1fcf1582479b9af1333b343a05dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5f862aff15be4a498e1fc940abbe9300": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ddc1fcf1582479b9af1333b343a05dd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b10d53b6ce274636861d4eec023ef593",
            "value": 1
          }
        },
        "67ffa802e2f84b039c6753208354c829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81414790fbee440899d7546ad873e9ee",
            "placeholder": "​",
            "style": "IPY_MODEL_b1ff947454694e3e90616eecd11e2a81",
            "value": " 51.0k/? [00:00&lt;00:00, 5.80MB/s]"
          }
        },
        "6c4979d7ca65461eb7eca4eb488a8b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13136ba2537140278819825bc851096f",
            "placeholder": "​",
            "style": "IPY_MODEL_7a51e251a2eb418ca55691c3eb145064",
            "value": "config.json: 100%"
          }
        },
        "6f2e7bc9eca440779df3190946ff50b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42693c5abef448f6b42b77d0ff4fb6da",
            "placeholder": "​",
            "style": "IPY_MODEL_cb8c575af1334815bea9df25ed167e85",
            "value": "generation_config.json: 100%"
          }
        },
        "7296f47ddf8047abbef40f516fb49656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f2e7bc9eca440779df3190946ff50b6",
              "IPY_MODEL_43c9e8f7408c4c27bc5e27b53386c6e7",
              "IPY_MODEL_8714ac68b5f64761b94f083905c2cfaf"
            ],
            "layout": "IPY_MODEL_fa00e8b2516642dbbf74062972836a78"
          }
        },
        "7a51e251a2eb418ca55691c3eb145064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81414790fbee440899d7546ad873e9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8714ac68b5f64761b94f083905c2cfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c40c4c2e4c844c39490a7c683176050",
            "placeholder": "​",
            "style": "IPY_MODEL_355feb2c92284209b4d1181e78c85d69",
            "value": " 172/172 [00:00&lt;00:00, 23.4kB/s]"
          }
        },
        "87a130b5a6fa4ff9949f6dabe4416494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9e32a2a2424b8c828d2fbca80ffaeb",
            "placeholder": "​",
            "style": "IPY_MODEL_0958981fb55c4f22ab3e6c95b150d488",
            "value": "tokenizer.json: "
          }
        },
        "89530df8d4df490a8b4697aae3e9ac1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b52263350949fba500062965415930": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dc6ccc0d0254bfd9c3d0f372b34842e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b2cb95c9a14e6ba577790db2616c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b10d53b6ce274636861d4eec023ef593": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1ff947454694e3e90616eecd11e2a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbe6597012d945afad7347b9ba85033c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ca299386784598b82d51c62071cd09",
            "placeholder": "​",
            "style": "IPY_MODEL_035d9167529e4957a1214c331f4ba7cd",
            "value": " 9.09M/? [00:00&lt;00:00, 95.4MB/s]"
          }
        },
        "c1f66bd198e3456c876d25c26115c24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec24da979bdd4d56b50480168875d4c5",
            "placeholder": "​",
            "style": "IPY_MODEL_a3b2cb95c9a14e6ba577790db2616c6b",
            "value": " 296/296 [00:00&lt;00:00, 37.9kB/s]"
          }
        },
        "c47e9b64fb4543fe81c0873f658c32e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c7ad1861c09140bbb1cf0e8813b736e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb8c575af1334815bea9df25ed167e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d213996ebd8f4772b553ff00665c8910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d38fa200fc824c39a6b26bcdfc28743e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c47e9b64fb4543fe81c0873f658c32e8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7ad1861c09140bbb1cf0e8813b736e7",
            "value": 1
          }
        },
        "def91e3891cb4fbfbd787ce942aea1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eacce3c626db42c3a734eca9041a1c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc72b3cc8b24ea49343347e5a1470a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89530df8d4df490a8b4697aae3e9ac1f",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54b6e6e9dd6a421797f4394299ed9359",
            "value": 727
          }
        },
        "ec24da979bdd4d56b50480168875d4c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ed0bd5bc0f4493b48fae8b7580d515": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa00e8b2516642dbbf74062972836a78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
