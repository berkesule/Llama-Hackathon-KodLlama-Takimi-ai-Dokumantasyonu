{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko2v8-fXwS8_",
        "outputId": "8a12eac4-8e09-42e8-9ada-cc5e4392b439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.12/dist-packages (from flask) (8.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from flask) (3.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ht72h9oKwME8",
        "outputId": "d1823b50-0233-4942-e17b-eef1cb66887f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting vllm\n",
            "  Downloading vllm-0.11.0-cp38-abi3-manylinux1_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from vllm) (2024.11.6)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from vllm) (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from vllm) (4.67.1)\n",
            "Collecting blake3 (from vllm)\n",
            "  Downloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.55.2 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.57.1)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.22.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from vllm) (5.29.5)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.119.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from vllm) (3.13.1)\n",
            "Requirement already satisfied: openai>=1.99.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.109.1)\n",
            "Requirement already satisfied: pydantic>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.11.10)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from vllm) (11.3.0)\n",
            "Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm)\n",
            "  Downloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.12.0)\n",
            "Collecting lm-format-enforcer==0.11.3 (from vllm)\n",
            "  Downloading lm_format_enforcer-0.11.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting llguidance<0.8.0,>=0.7.11 (from vllm)\n",
            "  Downloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting outlines_core==0.2.11 (from vllm)\n",
            "  Downloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting diskcache==5.6.3 (from vllm)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lark==1.2.2 (from vllm)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xgrammar==0.1.25 (from vllm)\n",
            "  Downloading xgrammar-0.1.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.15.0)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.12/dist-packages (from vllm) (3.20.0)\n",
            "Collecting partial-json-parser (from vllm)\n",
            "  Downloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (26.2.1)\n",
            "Collecting msgspec (from vllm)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting gguf>=0.13.0 (from vllm)\n",
            "  Downloading gguf-0.17.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting mistral_common>=1.8.2 (from mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading mistral_common-1.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (4.12.0.88)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from vllm) (6.0.3)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (1.17.0)\n",
            "Collecting setuptools<80,>=77.0.3 (from vllm)\n",
            "  Downloading setuptools-79.0.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from vllm) (0.8.1)\n",
            "Collecting compressed-tensors==0.11.0 (from vllm)\n",
            "  Downloading compressed_tensors-0.11.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting depyf==0.19.0 (from vllm)\n",
            "  Downloading depyf-0.19.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from vllm) (3.1.1)\n",
            "Collecting watchfiles (from vllm)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.12/dist-packages (from vllm) (4.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from vllm) (1.16.2)\n",
            "Collecting ninja (from vllm)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting pybase64 (from vllm)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting cbor2 (from vllm)\n",
            "  Downloading cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting setproctitle (from vllm)\n",
            "  Downloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (10 kB)\n",
            "Collecting openai-harmony>=0.0.3 (from vllm)\n",
            "  Downloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.0 kB)\n",
            "Collecting numba==0.61.2 (from vllm)\n",
            "  Downloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting ray>=2.48.0 (from ray[cgraph]>=2.48.0->vllm)\n",
            "  Downloading ray-2.50.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torchaudio==2.8.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision==0.23.0 in /usr/local/lib/python3.12/dist-packages (from vllm) (0.23.0+cu126)\n",
            "Collecting xformers==0.0.32.post1 (from vllm)\n",
            "  Downloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from compressed-tensors==0.11.0->vllm) (2.4.6)\n",
            "Collecting astor (from depyf==0.19.0->vllm)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from depyf==0.19.0->vllm) (0.3.8)\n",
            "Collecting interegular>=0.3.2 (from lm-format-enforcer==0.11.3->vllm)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lm-format-enforcer==0.11.3->vllm) (25.0)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba==0.61.2->vllm)\n",
            "  Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.48.0)\n",
            "Collecting fastapi-cli>=0.0.8 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cli-0.0.14-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.38.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (4.25.1)\n",
            "Collecting pydantic-extra-types>=2.10.5 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading pydantic_extra_types-2.10.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.99.1->vllm) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.7->vllm) (0.4.2)\n",
            "Collecting click!=8.3.0,>=7.0 (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm)\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray>=2.48.0->ray[cgraph]>=2.48.0->vllm) (1.1.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.12/dist-packages (from ray[cgraph]>=2.48.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->vllm) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.21.1->vllm) (0.35.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.55.2->vllm) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->vllm) (1.22.0)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typer>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.20.0)\n",
            "Collecting rich-toolkit>=0.14.8 (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rich_toolkit-0.15.1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fastapi-cloud-cli>=0.1.1 (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading fastapi_cloud_cli-0.3.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.21.1->vllm) (1.1.10)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.27.1)\n",
            "Collecting pycountry>=23 (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm)\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.12/dist-packages (from cupy-cuda12x->ray[cgraph]>=2.48.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (0.13.1)\n",
            "Requirement already satisfied: soxr>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (1.0.0)\n",
            "Collecting rignore>=0.5.1 (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm)\n",
            "  Downloading rignore-0.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: sentry-sdk>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.42.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.0.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->mistral_common>=1.8.2->mistral_common[audio,image]>=1.8.2->vllm) (2.23)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Downloading vllm-0.11.0-cp38-abi3-manylinux1_x86_64.whl (438.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m438.2/438.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading compressed_tensors-0.11.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m180.0/180.0 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading depyf-0.19.0-py3-none-any.whl (39 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_format_enforcer-0.11.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.2.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.32.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xgrammar-0.1.25-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Downloading gguf-0.17.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llguidance-0.7.30-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistral_common-1.8.5-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai_harmony-0.0.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading ray-2.50.1-cp312-cp312-manylinux2014_x86_64.whl (71.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.1/71.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setuptools-79.0.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blake3-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cbor2-5.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (285 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m285.7/285.7 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading partial_json_parser-0.2.1.1.post6-py3-none-any.whl (10 kB)\n",
            "Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.7-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (32 kB)\n",
            "Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading fastapi_cli-0.0.14-py3-none-any.whl (11 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading llvmlite-0.44.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_extra_types-2.10.6-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi_cloud_cli-0.3.1-py3-none-any.whl (19 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich_toolkit-0.15.1-py3-none-any.whl (29 kB)\n",
            "Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rignore-0.7.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (951 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m951.9/951.9 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, setuptools, setproctitle, rignore, pyngrok, pycountry, pybase64, partial-json-parser, outlines_core, ninja, msgspec, llvmlite, llguidance, lark, interegular, httptools, gguf, dnspython, diskcache, click, cbor2, blake3, astor, watchfiles, numba, email-validator, depyf, rich-toolkit, pydantic-extra-types, prometheus-fastapi-instrumentator, openai-harmony, lm-format-enforcer, xformers, ray, fastapi-cloud-cli, fastapi-cli, xgrammar, mistral_common, compressed-tensors, vllm\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.43.0\n",
            "    Uninstalling llvmlite-0.43.0:\n",
            "      Successfully uninstalled llvmlite-0.43.0\n",
            "  Attempting uninstall: lark\n",
            "    Found existing installation: lark 1.3.0\n",
            "    Uninstalling lark-1.3.0:\n",
            "      Successfully uninstalled lark-1.3.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.60.0\n",
            "    Uninstalling numba-0.60.0:\n",
            "      Successfully uninstalled numba-0.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astor-0.8.1 blake3-1.0.8 cbor2-5.7.1 click-8.2.1 compressed-tensors-0.11.0 depyf-0.19.0 diskcache-5.6.3 dnspython-2.8.0 email-validator-2.3.0 fastapi-cli-0.0.14 fastapi-cloud-cli-0.3.1 gguf-0.17.1 httptools-0.7.1 interegular-0.3.3 lark-1.2.2 llguidance-0.7.30 llvmlite-0.44.0 lm-format-enforcer-0.11.3 mistral_common-1.8.5 msgspec-0.19.0 ninja-1.13.0 numba-0.61.2 openai-harmony-0.0.4 outlines_core-0.2.11 partial-json-parser-0.2.1.1.post6 prometheus-fastapi-instrumentator-7.1.0 pybase64-1.4.2 pycountry-24.6.1 pydantic-extra-types-2.10.6 pyngrok-7.4.1 ray-2.50.1 rich-toolkit-0.15.1 rignore-0.7.1 setproctitle-1.3.7 setuptools-79.0.1 uvloop-0.22.1 vllm-0.11.0 watchfiles-1.1.1 xformers-0.0.32.post1 xgrammar-0.1.25\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6d08cf3b6af047b593ae72c2e1fba27e",
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install vllm torch pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEWOOOZdwVFf",
        "outputId": "dfbf7e4e-ac1f-4f8a-a831-f247e82cd3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok config add-authtoken YOUR_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "21ebcf507de347c29e90906c45c15ada",
            "6c4979d7ca65461eb7eca4eb488a8b4a",
            "ebc72b3cc8b24ea49343347e5a1470a1",
            "4fb9aa7e934d461ca27d17e4b5957a66",
            "89b52263350949fba500062965415930",
            "13136ba2537140278819825bc851096f",
            "7a51e251a2eb418ca55691c3eb145064",
            "89530df8d4df490a8b4697aae3e9ac1f",
            "54b6e6e9dd6a421797f4394299ed9359",
            "eacce3c626db42c3a734eca9041a1c3e",
            "0cb1f0a2c3074ed3b49669173863e91e",
            "4962839be8694716b76fb62db25cd5a4",
            "3d4cbb7b94ca463983616657ed97edfb",
            "d38fa200fc824c39a6b26bcdfc28743e",
            "67ffa802e2f84b039c6753208354c829",
            "48a44eb3f1744dd7a7a45c95c6daa133",
            "4305909b07e3486fb20e61d1b1cbd8a9",
            "def91e3891cb4fbfbd787ce942aea1fd",
            "c47e9b64fb4543fe81c0873f658c32e8",
            "c7ad1861c09140bbb1cf0e8813b736e7",
            "81414790fbee440899d7546ad873e9ee",
            "b1ff947454694e3e90616eecd11e2a81",
            "4fed7721fb7149f581b7541fc5c9bbc3",
            "87a130b5a6fa4ff9949f6dabe4416494",
            "5f862aff15be4a498e1fc940abbe9300",
            "bbe6597012d945afad7347b9ba85033c",
            "f3ed0bd5bc0f4493b48fae8b7580d515",
            "0f9e32a2a2424b8c828d2fbca80ffaeb",
            "0958981fb55c4f22ab3e6c95b150d488",
            "5ddc1fcf1582479b9af1333b343a05dd",
            "b10d53b6ce274636861d4eec023ef593",
            "27ca299386784598b82d51c62071cd09",
            "035d9167529e4957a1214c331f4ba7cd",
            "291dd1efc1404186ba08d84db19053e8",
            "520a55df250a44a09cb7291805fa5092",
            "0df87cb6227f4c408a3b2aca1a6f2e2f",
            "c1f66bd198e3456c876d25c26115c24f",
            "8dc6ccc0d0254bfd9c3d0f372b34842e",
            "292f007303a84864a404e81a4f6b7cf8",
            "245ccd89ff59408a99317e8156c941c4",
            "38b5738753df4a80b83f78b4e0a00447",
            "1bc5f7bf804648458237fc82bd9609f9",
            "ec24da979bdd4d56b50480168875d4c5",
            "a3b2cb95c9a14e6ba577790db2616c6b",
            "7296f47ddf8047abbef40f516fb49656",
            "6f2e7bc9eca440779df3190946ff50b6",
            "43c9e8f7408c4c27bc5e27b53386c6e7",
            "8714ac68b5f64761b94f083905c2cfaf",
            "fa00e8b2516642dbbf74062972836a78",
            "42693c5abef448f6b42b77d0ff4fb6da",
            "cb8c575af1334815bea9df25ed167e85",
            "3996038136af43a5986f47964104e456",
            "d213996ebd8f4772b553ff00665c8910",
            "4c40c4c2e4c844c39490a7c683176050",
            "355feb2c92284209b4d1181e78c85d69"
          ]
        },
        "id": "pybaIdSPt26N",
        "outputId": "5bc5b312-c8bb-46c2-adce-da3b9de2ce9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 10-25 20:02:31 [__init__.py:216] Automatically detected platform cuda.\n",
            "================================================================================\n",
            "üöÄ MODEL Y√úKLEME BA≈ûLIYOR...\n",
            "‚è∞ Zaman: 20:02:41\n",
            "================================================================================\n",
            "INFO 10-25 20:02:41 [utils.py:233] non-default args: {'trust_remote_code': True, 'dtype': 'float16', 'max_model_len': 4096, 'disable_log_stats': True, 'model': 'ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21ebcf507de347c29e90906c45c15ada",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 10-25 20:02:59 [model.py:547] Resolved architecture: LlamaForCausalLM\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 10-25 20:02:59 [model.py:1733] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 10-25 20:02:59 [model.py:1510] Using max model len 4096\n",
            "INFO 10-25 20:03:03 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4962839be8694716b76fb62db25cd5a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4fed7721fb7149f581b7541fc5c9bbc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "291dd1efc1404186ba08d84db19053e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7296f47ddf8047abbef40f516fb49656",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 10-25 20:03:04 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
            "INFO 10-25 20:05:40 [llm.py:306] Supported_tasks: ['generate']\n",
            "‚úÖ Model ba≈üarƒ±yla y√ºklendi!\n",
            "üîß GPU Kullanƒ±mƒ±: %90\n",
            "üìè Max Token: 4096\n",
            "‚úÖ Tokenizer hazƒ±r: CachedPreTrainedTokenizerFast\n",
            "\n",
            "================================================================================\n",
            "üåê NGROK BA≈ûLATILIYOR...\n",
            "================================================================================\n",
            "\n",
            "‚úÖ API HAZIR!\n",
            "üì° Public URL: NgrokTunnel: \"https://8d284d47fc62.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            "\n",
            "üîó Endpoints:\n",
            "   ‚Ä¢ Streaming: NgrokTunnel: \"https://8d284d47fc62.ngrok-free.app\" -> \"http://localhost:5000\"/api/generate\n",
            "   ‚Ä¢ Test: NgrokTunnel: \"https://8d284d47fc62.ngrok-free.app\" -> \"http://localhost:5000\"/api/test\n",
            "   ‚Ä¢ Health: NgrokTunnel: \"https://8d284d47fc62.ngrok-free.app\" -> \"http://localhost:5000\"/health\n",
            "\n",
            "================================================================================\n",
            "üöÄ FLASK SERVER BA≈ûLATILIYOR...\n",
            "================================================================================\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:06:08\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 448 byte\n",
            "‚úÖ Proje anahtarƒ±: INSIGHT\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1866 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:06:08.611\n",
            "üìä Prompt uzunluƒüu: 1866 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:06:20] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 3122 karakter\n",
            "üìè Token sayƒ±sƒ±: ~409\n",
            "‚è±Ô∏è √úretim s√ºresi: 12.11 saniye\n",
            "üöÄ Hƒ±z: 257.9 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**INSIGHT Projesinin Durum Raporu**\n",
            "\n",
            "---\n",
            "\n",
            "**PROJE √ñZET:**\n",
            "Projenizin toplamda 3 g√∂revden olu≈ütuƒüu g√∂r√ºlmektedir. G√∂revler ≈üu anda √º√ß ki≈üilik ekibiniz tarafƒ±ndan y√ºr√ºt√ºl√ºyor; Jon (arka u√ß), Joe (√∂n u√ß)...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 6.4% (200/3122)\n",
            "üì§ Stream ilerleme: 12.8% (400/3122)\n",
            "üì§ Stream ilerleme: 19.2% (600/3122)\n",
            "üì§ Stream ilerleme: 25.6% (800/3122)\n",
            "üì§ Stream ilerleme: 32.0% (1000/3122)\n",
            "üì§ Stream ilerleme: 38.4% (1200/3122)\n",
            "üì§ Stream ilerleme: 44.8% (1400/3122)\n",
            "üì§ Stream ilerleme: 51.2% (1600/3122)\n",
            "üì§ Stream ilerleme: 57.7% (1800/3122)\n",
            "üì§ Stream ilerleme: 64.1% (2000/3122)\n",
            "üì§ Stream ilerleme: 70.5% (2200/3122)\n",
            "üì§ Stream ilerleme: 76.9% (2400/3122)\n",
            "üì§ Stream ilerleme: 83.3% (2600/3122)\n",
            "üì§ Stream ilerleme: 89.7% (2800/3122)\n",
            "üì§ Stream ilerleme: 96.1% (3000/3122)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 3.96 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 16.07 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:07:48\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 448 byte\n",
            "‚úÖ Proje anahtarƒ±: INSIGHT\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1866 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:07:48.878\n",
            "üìä Prompt uzunluƒüu: 1866 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:07:57] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2115 karakter\n",
            "üìè Token sayƒ±sƒ±: ~265\n",
            "‚è±Ô∏è √úretim s√ºresi: 8.46 saniye\n",
            "üöÄ Hƒ±z: 250.1 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "* **Toplam G√∂rev Sayƒ±sƒ±:** Verilen verilerde 3 g√∂rev bulunmaktadƒ±r.\n",
            "* **Durum Daƒüƒ±lƒ±mƒ±:**\n",
            "\t+ ƒ∞n Progress (2): Backend API geli≈ütirmede Jon ile Frontend UI'deki Joe √ßalƒ±≈ümaktadƒ±r.\n",
            "\t+ ...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 9.5% (200/2115)\n",
            "üì§ Stream ilerleme: 18.9% (400/2115)\n",
            "üì§ Stream ilerleme: 28.4% (600/2115)\n",
            "üì§ Stream ilerleme: 37.8% (800/2115)\n",
            "üì§ Stream ilerleme: 47.3% (1000/2115)\n",
            "üì§ Stream ilerleme: 56.7% (1200/2115)\n",
            "üì§ Stream ilerleme: 66.2% (1400/2115)\n",
            "üì§ Stream ilerleme: 75.7% (1600/2115)\n",
            "üì§ Stream ilerleme: 85.1% (1800/2115)\n",
            "üì§ Stream ilerleme: 94.6% (2000/2115)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 2.69 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 11.14 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:09:33\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 448 byte\n",
            "‚úÖ Proje anahtarƒ±: INSIGHT\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1866 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:09:33.746\n",
            "üìä Prompt uzunluƒüu: 1866 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:09:44] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2910 karakter\n",
            "üìè Token sayƒ±sƒ±: ~357\n",
            "‚è±Ô∏è √úretim s√ºresi: 10.91 saniye\n",
            "üöÄ Hƒ±z: 266.7 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "* **Toplam G√∂rev Sayƒ±sƒ±:** 3 g√∂rev\n",
            "* **Durum Daƒüƒ±lƒ±mƒ±:** \n",
            "\t+ In Progress (2): Backend API geli≈ütirme ve Frontend UI\n",
            "\t+ Completed (1): Design mockuplarƒ±\n",
            "* **Tamamlanma Y√ºzdesi:** %33 ...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 6.9% (200/2910)\n",
            "üì§ Stream ilerleme: 13.7% (400/2910)\n",
            "üì§ Stream ilerleme: 20.6% (600/2910)\n",
            "üì§ Stream ilerleme: 27.5% (800/2910)\n",
            "üì§ Stream ilerleme: 34.4% (1000/2910)\n",
            "üì§ Stream ilerleme: 41.2% (1200/2910)\n",
            "üì§ Stream ilerleme: 48.1% (1400/2910)\n",
            "üì§ Stream ilerleme: 55.0% (1600/2910)\n",
            "üì§ Stream ilerleme: 61.9% (1800/2910)\n",
            "üì§ Stream ilerleme: 68.7% (2000/2910)\n",
            "üì§ Stream ilerleme: 75.6% (2200/2910)\n",
            "üì§ Stream ilerleme: 82.5% (2400/2910)\n",
            "üì§ Stream ilerleme: 89.3% (2600/2910)\n",
            "üì§ Stream ilerleme: 96.2% (2800/2910)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 3.69 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 14.60 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:18:13] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:39:29] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:39:30] \"\u001b[31m\u001b[1mPOST /api/generate HTTP/1.1\u001b[0m\" 400 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:39:30\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚ùå JSON girdisi bulunamadƒ±!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:39:44] \"\u001b[31m\u001b[1mGET /api/generate HTTP/1.1\u001b[0m\" 405 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:40:07\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 448 byte\n",
            "‚úÖ Proje anahtarƒ±: INSIGHT\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1866 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:40:07.460\n",
            "üìä Prompt uzunluƒüu: 1866 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:40:13] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:40:16] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2118 karakter\n",
            "üìè Token sayƒ±sƒ±: ~270\n",
            "‚è±Ô∏è √úretim s√ºresi: 8.80 saniye\n",
            "üöÄ Hƒ±z: 240.6 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**PROJE √ñZET:**\n",
            "\n",
            "* **Proje Adƒ±:** AI G√ºd√ºml√º √ñƒürenme Aracƒ± (AI Powered Learning Tool)\n",
            "* **T√ºr:** Eƒüitim Ara√ßlarƒ±\n",
            "* **Hedef:** √áocuklarƒ±n kodlamayƒ± √∂ƒürenmesine yardƒ±mcƒ± olmak i√ßin geli≈ütirdiƒüimiz bir a...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 9.4% (200/2118)\n",
            "üì§ Stream ilerleme: 18.9% (400/2118)\n",
            "üì§ Stream ilerleme: 28.3% (600/2118)\n",
            "üì§ Stream ilerleme: 37.8% (800/2118)\n",
            "üì§ Stream ilerleme: 47.2% (1000/2118)\n",
            "üì§ Stream ilerleme: 56.7% (1200/2118)\n",
            "üì§ Stream ilerleme: 66.1% (1400/2118)\n",
            "üì§ Stream ilerleme: 75.5% (1600/2118)\n",
            "üì§ Stream ilerleme: 85.0% (1800/2118)\n",
            "üì§ Stream ilerleme: 94.4% (2000/2118)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 2.69 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 11.49 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:40:20] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:42:31] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:43:11] \"\u001b[33mPOST / HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:44:33\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 498 byte\n",
            "‚úÖ Proje anahtarƒ±: p02\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1928 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:44:33.807\n",
            "üìä Prompt uzunluƒüu: 1928 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:44:43] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2727 karakter\n",
            "üìè Token sayƒ±sƒ±: ~330\n",
            "‚è±Ô∏è √úretim s√ºresi: 9.84 saniye\n",
            "üöÄ Hƒ±z: 277.0 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "Bu raporda, build edilen mobil uygulamanƒ±n iOS ve Android platformlarƒ± i√ßin (proje_description) incelenmektedir. ≈ûu anda iki ekip √ºyesinin olduƒüu takƒ±m bilgisi verilmemektedir. G√∂rev...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 7.3% (200/2727)\n",
            "üì§ Stream ilerleme: 14.7% (400/2727)\n",
            "üì§ Stream ilerleme: 22.0% (600/2727)\n",
            "üì§ Stream ilerleme: 29.3% (800/2727)\n",
            "üì§ Stream ilerleme: 36.7% (1000/2727)\n",
            "üì§ Stream ilerleme: 44.0% (1200/2727)\n",
            "üì§ Stream ilerleme: 51.3% (1400/2727)\n",
            "üì§ Stream ilerleme: 58.7% (1600/2727)\n",
            "üì§ Stream ilerleme: 66.0% (1800/2727)\n",
            "üì§ Stream ilerleme: 73.3% (2000/2727)\n",
            "üì§ Stream ilerleme: 80.7% (2200/2727)\n",
            "üì§ Stream ilerleme: 88.0% (2400/2727)\n",
            "üì§ Stream ilerleme: 95.3% (2600/2727)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 3.46 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 13.30 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:45:03\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 498 byte\n",
            "‚úÖ Proje anahtarƒ±: p02\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1928 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:45:03.625\n",
            "üìä Prompt uzunluƒüu: 1928 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:45:11] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2102 karakter\n",
            "üìè Token sayƒ±sƒ±: ~257\n",
            "‚è±Ô∏è √úretim s√ºresi: 7.97 saniye\n",
            "üöÄ Hƒ±z: 263.8 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "* **Toplam G√∂rev Sayƒ±sƒ±:** 4 g√∂rev bulunmaktadƒ±r.\n",
            "* **Durum Daƒüƒ±lƒ±mƒ±:**\n",
            "\t+ Pending Durumu: 2 (50%)\n",
            "\t+ Completed Durumu: 2 (50%)\n",
            "\n",
            "Tamamlama Y√ºzdesi: %100 (%)\n",
            "\n",
            "---\n",
            "\n",
            "**Riskler ve Dikkat...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 9.5% (200/2102)\n",
            "üì§ Stream ilerleme: 19.0% (400/2102)\n",
            "üì§ Stream ilerleme: 28.5% (600/2102)\n",
            "üì§ Stream ilerleme: 38.1% (800/2102)\n",
            "üì§ Stream ilerleme: 47.6% (1000/2102)\n",
            "üì§ Stream ilerleme: 57.1% (1200/2102)\n",
            "üì§ Stream ilerleme: 66.6% (1400/2102)\n",
            "üì§ Stream ilerleme: 76.1% (1600/2102)\n",
            "üì§ Stream ilerleme: 85.6% (1800/2102)\n",
            "üì§ Stream ilerleme: 95.1% (2000/2102)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 2.67 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 10.63 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:45:59\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 498 byte\n",
            "‚úÖ Proje anahtarƒ±: p02\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1928 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:45:59.093\n",
            "üìä Prompt uzunluƒüu: 1928 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:46:09] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2614 karakter\n",
            "üìè Token sayƒ±sƒ±: ~323\n",
            "‚è±Ô∏è √úretim s√ºresi: 9.97 saniye\n",
            "üöÄ Hƒ±z: 262.3 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**PROJE √ñZET:**\n",
            "\n",
            "* **Toplam G√∂rev Sayƒ±sƒ±:** 4 g√∂rev bulunmaktadƒ±r.\n",
            "* **Durum Daƒüƒ±lƒ±mƒ±:** Tamamlanan g√∂revler %50 (%2) ile birlikte toplamda %75'e tekab√ºl ederken, kalan g√∂revler %25'ini olu≈üturmaktadƒ±...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:46:18\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 498 byte\n",
            "‚úÖ Proje anahtarƒ±: p02\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1928 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:46:18.341\n",
            "üìä Prompt uzunluƒüu: 1928 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:46:28] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2749 karakter\n",
            "üìè Token sayƒ±sƒ±: ~325\n",
            "‚è±Ô∏è √úretim s√ºresi: 10.35 saniye\n",
            "üöÄ Hƒ±z: 265.5 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**PROJE √ñZET:**\n",
            "\n",
            "Proje a√ßƒ±klamasƒ±na g√∂re, bu proje mobil uygulamanƒ±n hem iOS hem de Android platformlarƒ± i√ßin geli≈ütirilmesi ile ilgilidir. Verilen bilgilerden yola √ßƒ±karak a≈üaƒüƒ±daki sonu√ßlara varabil...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 7.3% (200/2749)\n",
            "üì§ Stream ilerleme: 14.6% (400/2749)\n",
            "üì§ Stream ilerleme: 21.8% (600/2749)\n",
            "üì§ Stream ilerleme: 29.1% (800/2749)\n",
            "üì§ Stream ilerleme: 36.4% (1000/2749)\n",
            "üì§ Stream ilerleme: 43.7% (1200/2749)\n",
            "üì§ Stream ilerleme: 50.9% (1400/2749)\n",
            "üì§ Stream ilerleme: 58.2% (1600/2749)\n",
            "üì§ Stream ilerleme: 65.5% (1800/2749)\n",
            "üì§ Stream ilerleme: 72.8% (2000/2749)\n",
            "üì§ Stream ilerleme: 80.0% (2200/2749)\n",
            "üì§ Stream ilerleme: 87.3% (2400/2749)\n",
            "üì§ Stream ilerleme: 94.6% (2600/2749)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 3.49 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 13.84 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:46:59\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 498 byte\n",
            "‚úÖ Proje anahtarƒ±: p02\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1928 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:46:59.018\n",
            "üìä Prompt uzunluƒüu: 1928 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:47:06] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2170 karakter\n",
            "üìè Token sayƒ±sƒ±: ~270\n",
            "‚è±Ô∏è √úretim s√ºresi: 7.88 saniye\n",
            "üöÄ Hƒ±z: 275.4 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "**Toplam G√∂rev Sayƒ±sƒ±:** 4 adet\n",
            "\n",
            "**Durum Daƒüƒ±lƒ±mƒ±:**\n",
            "- Tamamlandƒ±: 1 (25%)\n",
            "- Bekleyen: 3 (75%)\n",
            "\n",
            "**Tamamlama Y√ºzdesi:** %25\n",
            "\n",
            "---\n",
            "\n",
            "**Riskler ve Dikkate Alƒ±nacak Hususlar:**\n",
            "\n",
            "* **Kritik...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 9.2% (200/2170)\n",
            "üì§ Stream ilerleme: 18.4% (400/2170)\n",
            "üì§ Stream ilerleme: 27.6% (600/2170)\n",
            "üì§ Stream ilerleme: 36.9% (800/2170)\n",
            "üì§ Stream ilerleme: 46.1% (1000/2170)\n",
            "üì§ Stream ilerleme: 55.3% (1200/2170)\n",
            "üì§ Stream ilerleme: 64.5% (1400/2170)\n",
            "üì§ Stream ilerleme: 73.7% (1600/2170)\n",
            "üì§ Stream ilerleme: 82.9% (1800/2170)\n",
            "üì§ Stream ilerleme: 92.2% (2000/2170)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 2.76 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 10.64 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:53:59\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 498 byte\n",
            "‚úÖ Proje anahtarƒ±: p02\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 1928 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:53:59.188\n",
            "üìä Prompt uzunluƒüu: 1928 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:54:10] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2931 karakter\n",
            "üìè Token sayƒ±sƒ±: ~374\n",
            "‚è±Ô∏è √úretim s√ºresi: 10.90 saniye\n",
            "üöÄ Hƒ±z: 268.8 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "Bu raporda \"iOS ve Android mobil uygulamasƒ±nƒ±n geli≈ütirilmesi\" olan p02 adlƒ± bir proje incelenecektir. A≈üaƒüƒ±da proje √∂zetinin ve ilgili ayrƒ±ntƒ±larƒ±n yer aldƒ±ƒüƒ± bir tablo bulunmaktadƒ±...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 6.8% (200/2931)\n",
            "üì§ Stream ilerleme: 13.6% (400/2931)\n",
            "üì§ Stream ilerleme: 20.5% (600/2931)\n",
            "üì§ Stream ilerleme: 27.3% (800/2931)\n",
            "üì§ Stream ilerleme: 34.1% (1000/2931)\n",
            "üì§ Stream ilerleme: 40.9% (1200/2931)\n",
            "üì§ Stream ilerleme: 47.8% (1400/2931)\n",
            "üì§ Stream ilerleme: 54.6% (1600/2931)\n",
            "üì§ Stream ilerleme: 61.4% (1800/2931)\n",
            "üì§ Stream ilerleme: 68.2% (2000/2931)\n",
            "üì§ Stream ilerleme: 75.1% (2200/2931)\n",
            "üì§ Stream ilerleme: 81.9% (2400/2931)\n",
            "üì§ Stream ilerleme: 88.7% (2600/2931)\n",
            "üì§ Stream ilerleme: 95.5% (2800/2931)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 3.72 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 14.63 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:55:30\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 647 byte\n",
            "‚úÖ Proje anahtarƒ±: p987\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 2105 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:55:30.614\n",
            "üìä Prompt uzunluƒüu: 2105 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:55:38] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 1965 karakter\n",
            "üìè Token sayƒ±sƒ±: ~243\n",
            "‚è±Ô∏è √úretim s√ºresi: 7.78 saniye\n",
            "üöÄ Hƒ±z: 252.5 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "Proje Adƒ±: Planlama Uygulamasƒ±\n",
            "\n",
            "Toplam G√∂rev Sayƒ±sƒ±: 5\n",
            "\n",
            "Durum Daƒüƒ±lƒ±mƒ±:\n",
            "\n",
            "* Bekleyen g√∂revler: %100 (Be≈ü g√∂revin tamamƒ±nda status 'Bekleniyor')\n",
            "\n",
            "Tamamlanma Y√ºzdesi: %0\n",
            "\n",
            "**Riskler ve D...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 10.2% (200/1965)\n",
            "üì§ Stream ilerleme: 20.4% (400/1965)\n",
            "üì§ Stream ilerleme: 30.5% (600/1965)\n",
            "üì§ Stream ilerleme: 40.7% (800/1965)\n",
            "üì§ Stream ilerleme: 50.9% (1000/1965)\n",
            "üì§ Stream ilerleme: 61.1% (1200/1965)\n",
            "üì§ Stream ilerleme: 71.2% (1400/1965)\n",
            "üì§ Stream ilerleme: 81.4% (1600/1965)\n",
            "üì§ Stream ilerleme: 91.6% (1800/1965)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 2.49 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 10.27 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:55:56\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 647 byte\n",
            "‚úÖ Proje anahtarƒ±: p987\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 2105 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:55:56.492\n",
            "üìä Prompt uzunluƒüu: 2105 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:55:59\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 647 byte\n",
            "‚úÖ Proje anahtarƒ±: p987\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 2105 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:55:59.000\n",
            "üìä Prompt uzunluƒüu: 2105 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:56:00\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 647 byte\n",
            "‚úÖ Proje anahtarƒ±: p987\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 2105 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:56:00.701\n",
            "üìä Prompt uzunluƒüu: 2105 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:56:09] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2170 karakter\n",
            "üìè Token sayƒ±sƒ±: ~277\n",
            "‚è±Ô∏è √úretim s√ºresi: 13.34 saniye\n",
            "üöÄ Hƒ±z: 162.7 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "Verilen P987 projesinin toplamda 5 g√∂revi bulunmaktadƒ±r. G√∂revlerin tamamƒ±nda da \"Bekleme\" (Pending) olarak durumdadƒ±r. Bu nedenle proje genelinde %0 tamamlanma oranƒ±na sahip olduƒüun...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:56:47\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 647 byte\n",
            "‚úÖ Proje anahtarƒ±: p987\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 2105 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:56:47.383\n",
            "üìä Prompt uzunluƒüu: 2105 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:56:49\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 647 byte\n",
            "‚úÖ Proje anahtarƒ±: p987\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 2105 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:56:49.442\n",
            "üìä Prompt uzunluƒüu: 2105 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:56:59] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 3092 karakter\n",
            "üìè Token sayƒ±sƒ±: ~385\n",
            "‚è±Ô∏è √úretim s√ºresi: 9.79 saniye\n",
            "üöÄ Hƒ±z: 315.9 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**PROJE RAPORU:**\n",
            "\n",
            "**Proje √ñzeti:**\n",
            "Projenin adƒ± \"Planlama Uygulamasƒ±\" olup, planlama uygulamanƒ±zƒ±n tasarƒ±mƒ±, geli≈ütirilmesi, test edilmesi ve daƒüƒ±tƒ±lmasƒ±nƒ± i√ßermektedir. ≈ûu anda toplamda 5 g√∂rev bulu...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üì§ Stream ilerleme: 6.5% (200/3092)\n",
            "üì§ Stream ilerleme: 12.9% (400/3092)\n",
            "üì§ Stream ilerleme: 19.4% (600/3092)\n",
            "üì§ Stream ilerleme: 25.9% (800/3092)\n",
            "üì§ Stream ilerleme: 32.3% (1000/3092)\n",
            "üì§ Stream ilerleme: 38.8% (1200/3092)\n",
            "üì§ Stream ilerleme: 45.3% (1400/3092)\n",
            "üì§ Stream ilerleme: 51.7% (1600/3092)\n",
            "üì§ Stream ilerleme: 58.2% (1800/3092)\n",
            "üì§ Stream ilerleme: 64.7% (2000/3092)\n",
            "üì§ Stream ilerleme: 71.2% (2200/3092)\n",
            "üì§ Stream ilerleme: 77.6% (2400/3092)\n",
            "üì§ Stream ilerleme: 84.1% (2600/3092)\n",
            "üì§ Stream ilerleme: 90.6% (2800/3092)\n",
            "üì§ Stream ilerleme: 97.0% (3000/3092)\n",
            "\n",
            "‚úÖ STREAMING TAMAMLANDI!\n",
            "‚è±Ô∏è Stream s√ºresi: 3.92 saniye\n",
            "‚è±Ô∏è Toplam s√ºre: 13.71 saniye\n",
            "================================================================================\n",
            "\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n",
            "\n",
            "================================================================================\n",
            "üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\n",
            "‚è∞ Zaman: 20:58:01\n",
            "================================================================================\n",
            "üîç Veri doƒürulanƒ±yor...\n",
            "‚úÖ JSON verisi alƒ±ndƒ± - Boyut: 647 byte\n",
            "‚úÖ Proje anahtarƒ±: p987\n",
            "‚úÖ Veri tipi: <class 'dict'>\n",
            "üìù Prompt olu≈üturuluyor...\n",
            "‚úÖ Chat template uygulandƒ±\n",
            "‚úÖ Prompt hazƒ±r - Uzunluk: 2105 karakter\n",
            "üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\n",
            "\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "ü§ñ MODEL √áALI≈ûIYOR...\n",
            "‚è∞ Ba≈ülangƒ±√ß: 20:58:01.570\n",
            "üìä Prompt uzunluƒüu: 2105 karakter\n",
            "üéöÔ∏è Temperature: 0.7\n",
            "üéØ Max tokens: 2048\n",
            "üõë Stop tokens: []\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [25/Oct/2025 20:58:10] \"POST /api/generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üèÅ Finish Reason: stop\n",
            "\n",
            "‚úÖ MODEL √áIKTI √úRETTƒ∞!\n",
            "üìè √áƒ±ktƒ± uzunluƒüu: 2683 karakter\n",
            "üìè Token sayƒ±sƒ±: ~318\n",
            "‚è±Ô∏è √úretim s√ºresi: 129.33 saniye\n",
            "üöÄ Hƒ±z: 20.7 karakter/saniye\n",
            "\n",
            "üìñ √ñnizleme:\n",
            "**Proje √ñzeti:**\n",
            "\n",
            "p987 Projesinin √∂zetini inceleyerek toplamda be≈ü adet g√∂reve sahip olduƒüunu g√∂r√ºyoruz. G√∂revlerin tamamƒ±na bakarak bu projede hala planlama uygulamasƒ±nƒ±n olu≈üturma s√ºrecinde olduƒüumu...\n",
            "üîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑüîÑ\n",
            "\n",
            "üì° STREAMING BA≈ûLIYOR...\n",
            "üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\n",
            "‚úÖ Bellek temizlendi\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from flask import Flask, request, jsonify, Response, stream_with_context\n",
        "from vllm import LLM, SamplingParams\n",
        "import json\n",
        "import gc\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# ============================================================================\n",
        "# MODEL Y√úKLEME\n",
        "# ============================================================================\n",
        "print(\"=\" * 80)\n",
        "print(\"üöÄ MODEL Y√úKLEME BA≈ûLIYOR...\")\n",
        "print(f\"‚è∞ Zaman: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    llm_planner = LLM(\n",
        "        model=\"ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1\",\n",
        "        trust_remote_code=True,\n",
        "        gpu_memory_utilization=0.90,\n",
        "        max_model_len=4096,\n",
        "        dtype=\"float16\"\n",
        "    )\n",
        "    print(\"‚úÖ Model ba≈üarƒ±yla y√ºklendi!\")\n",
        "    print(f\"üîß GPU Kullanƒ±mƒ±: %90\")\n",
        "    print(f\"üìè Max Token: 4096\")\n",
        "\n",
        "    # Tokenizer'ƒ± al (chat template i√ßin)\n",
        "    tokenizer = llm_planner.get_tokenizer()\n",
        "    print(f\"‚úÖ Tokenizer hazƒ±r: {tokenizer.__class__.__name__}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Model y√ºkleme hatasƒ±: {e}\")\n",
        "    raise\n",
        "\n",
        "# ============================================================================\n",
        "# Sƒ∞STEM PROMPTU\n",
        "# ============================================================================\n",
        "SYSTEM_PROMPT = \"\"\"Sen uzman bir proje analiz asistanƒ±sƒ±n. G√∂r√ºvin Jira verilerini analiz edip projenin mevcut durumu hakkƒ±nda detaylƒ±, yapƒ±cƒ± ve net deƒüerlendirmeler yapmak.\n",
        "\n",
        "G√ñREV TANIMLARIN:\n",
        "1. Proje Saƒülƒ±ƒüƒ± Deƒüerlendirmesi - Issue durumlarƒ±nƒ± analiz et\n",
        "2. Risk Tespiti - Gecikmeler, bloke durumlar, atanmamƒ±≈ü i≈üleri belirle\n",
        "3. Sprint Performansƒ± - ƒ∞lerlemeyi ve hedeflere ula≈ümayƒ± deƒüerlendir\n",
        "4. Kaynak Daƒüƒ±lƒ±mƒ± - Ekip i≈ü y√ºk√º daƒüƒ±lƒ±mƒ±nƒ± incele\n",
        "5. √ñncelik Analizi - Y√ºksek √∂ncelikli g√∂revleri kontrol et\n",
        "\n",
        "√áIKTI FORMATI:\n",
        "\n",
        "PROJE √ñZET:\n",
        "- Toplam g√∂rev sayƒ±sƒ± ve durum daƒüƒ±lƒ±mƒ±\n",
        "- Tamamlanma y√ºzdesi\n",
        "\n",
        "Rƒ∞SKLER VE Dƒ∞KKAT GEREKENLER:\n",
        "- Kritik riskler\n",
        "- Gecikmeler\n",
        "- Bloke durumlar\n",
        "\n",
        "√ñNCELƒ∞K DURUMU:\n",
        "- Y√ºksek √∂ncelikli g√∂revlerin durumu\n",
        "- Acil m√ºdahale gereken konular\n",
        "\n",
        "EKƒ∞P PERFORMANSI:\n",
        "- ƒ∞≈ü y√ºk√º daƒüƒ±lƒ±mƒ±\n",
        "- Atanmamƒ±≈ü g√∂revler\n",
        "\n",
        "√ñNERƒ∞LER:\n",
        "- Kƒ±sa vadeli aksiyon √∂nerileri\n",
        "- S√ºre√ß iyile≈ütirme √∂nerileri\n",
        "\n",
        "Net, anla≈üƒ±lƒ±r ve T√ºrk√ße yaz. Rakamlarla destekle.\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# YARDIMCI FONKSƒ∞YONLAR\n",
        "# ============================================================================\n",
        "def format_chat_prompt(system_msg: str, user_msg: str) -> str:\n",
        "    \"\"\"Chat template ile prompt formatla\"\"\"\n",
        "    try:\n",
        "        # Llama chat format\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\", \"content\": user_msg}\n",
        "        ]\n",
        "\n",
        "        # Tokenizer'ƒ±n chat template'i varsa kullan\n",
        "        if hasattr(tokenizer, 'apply_chat_template'):\n",
        "            formatted = tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "            print(\"‚úÖ Chat template uygulandƒ±\")\n",
        "            return formatted\n",
        "        else:\n",
        "            # Manuel format (Llama style)\n",
        "            formatted = f\"<s>[INST] <<SYS>>\\n{system_msg}\\n<</SYS>>\\n\\n{user_msg} [/INST]\"\n",
        "            print(\"‚úÖ Manuel Llama format uygulandƒ±\")\n",
        "            return formatted\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Chat template hatasƒ±: {e}\")\n",
        "        # Fallback: basit format\n",
        "        return f\"{system_msg}\\n\\n{user_msg}\\n\\nYanƒ±t:\"\n",
        "\n",
        "def create_analysis_prompt(json_data: dict, project_key: str) -> str:\n",
        "    \"\"\"JSON verisini analiz i√ßin prompt haline getirir\"\"\"\n",
        "    try:\n",
        "        print(f\"üìù Prompt olu≈üturuluyor...\")\n",
        "        json_str = json.dumps(json_data, indent=2, ensure_ascii=False)\n",
        "\n",
        "        user_message = f\"\"\"A≈üaƒüƒ±daki {project_key} projesi verilerini analiz et ve belirlenen formatta detaylƒ± bir rapor hazƒ±rla.\n",
        "\n",
        "PROJE VERƒ∞LERƒ∞:\n",
        "{json_str}\n",
        "\n",
        "L√ºtfen yukarƒ±daki verileri dikkatlice analiz edip tam ve detaylƒ± bir rapor olu≈ütur. Her ba≈ülƒ±k altƒ±nda somut bulgular ve √∂neriler sun.\"\"\"\n",
        "\n",
        "        prompt = format_chat_prompt(SYSTEM_PROMPT, user_message)\n",
        "\n",
        "        print(f\"‚úÖ Prompt hazƒ±r - Uzunluk: {len(prompt)} karakter\")\n",
        "        return prompt\n",
        "    except Exception as e:\n",
        "        error_msg = f\"‚ùå Prompt olu≈üturma hatasƒ±: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "def generate_streaming_response(prompt: str):\n",
        "    \"\"\"vLLM ile streaming text √ºretir\"\"\"\n",
        "\n",
        "    # D√úZELTƒ∞LMƒ∞≈û SAMPLING PARAMETRELERƒ∞\n",
        "    sampling_params = SamplingParams(\n",
        "        temperature=0.7,           # Biraz daha yaratƒ±cƒ±\n",
        "        top_p=0.95,\n",
        "        top_k=50,\n",
        "        max_tokens=2048,           # Daha uzun √ßƒ±ktƒ± i√ßin\n",
        "        repetition_penalty=1.15,   # Tekrarƒ± azalt\n",
        "        presence_penalty=0.1,      # √áe≈üitliliƒüi artƒ±r\n",
        "        frequency_penalty=0.1,\n",
        "        stop=None,                 # Stop token'larƒ± kaldƒ±r!\n",
        "        skip_special_tokens=True   # √ñzel token'larƒ± atla\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(\"\\n\" + \"üîÑ\" * 40)\n",
        "        print(f\"ü§ñ MODEL √áALI≈ûIYOR...\")\n",
        "        print(f\"‚è∞ Ba≈ülangƒ±√ß: {datetime.now().strftime('%H:%M:%S.%f')[:-3]}\")\n",
        "        print(f\"üìä Prompt uzunluƒüu: {len(prompt)} karakter\")\n",
        "        print(f\"üéöÔ∏è Temperature: {sampling_params.temperature}\")\n",
        "        print(f\"üéØ Max tokens: {sampling_params.max_tokens}\")\n",
        "        print(f\"üõë Stop tokens: {sampling_params.stop}\")\n",
        "\n",
        "        # Model √ºretimi\n",
        "        start_time = time.time()\n",
        "        outputs = llm_planner.generate([prompt], sampling_params, use_tqdm=False)\n",
        "        generation_time = time.time() - start_time\n",
        "\n",
        "        full_text = outputs[0].outputs[0].text.strip()\n",
        "\n",
        "        # Debug: finish reason kontrol et\n",
        "        finish_reason = outputs[0].outputs[0].finish_reason\n",
        "        print(f\"\\nüèÅ Finish Reason: {finish_reason}\")\n",
        "\n",
        "        print(f\"\\n‚úÖ MODEL √áIKTI √úRETTƒ∞!\")\n",
        "        print(f\"üìè √áƒ±ktƒ± uzunluƒüu: {len(full_text)} karakter\")\n",
        "        print(f\"üìè Token sayƒ±sƒ±: ~{len(full_text.split())}\")\n",
        "        print(f\"‚è±Ô∏è √úretim s√ºresi: {generation_time:.2f} saniye\")\n",
        "        print(f\"üöÄ Hƒ±z: {len(full_text)/generation_time:.1f} karakter/saniye\")\n",
        "\n",
        "        # ƒ∞lk 200 karakteri g√∂ster\n",
        "        preview = full_text[:200] + \"...\" if len(full_text) > 200 else full_text\n",
        "        print(f\"\\nüìñ √ñnizleme:\\n{preview}\")\n",
        "        print(\"üîÑ\" * 40 + \"\\n\")\n",
        "\n",
        "        # Streaming ba≈ülangƒ±cƒ±\n",
        "        print(\"üì° STREAMING BA≈ûLIYOR...\")\n",
        "        stream_start = time.time()\n",
        "\n",
        "        # Metni chunk'lar halinde stream et\n",
        "        chunk_size = 8  # Her seferde 8 karakter\n",
        "        for i in range(0, len(full_text), chunk_size):\n",
        "            chunk = full_text[i:i+chunk_size]\n",
        "            yield f\"data: {json.dumps({'text': chunk, 'done': False}, ensure_ascii=False)}\\n\\n\"\n",
        "\n",
        "            # Her 200 karakterde bir durum raporu\n",
        "            if i % 200 == 0 and i > 0:\n",
        "                progress = (i / len(full_text)) * 100\n",
        "                print(f\"üì§ Stream ilerleme: {progress:.1f}% ({i}/{len(full_text)})\")\n",
        "\n",
        "            time.sleep(0.01)  # Smooth streaming\n",
        "\n",
        "        stream_time = time.time() - stream_start\n",
        "\n",
        "        # Tamamlandƒ± sinyali\n",
        "        yield f\"data: {json.dumps({'text': '', 'done': True})}\\n\\n\"\n",
        "\n",
        "        print(f\"\\n‚úÖ STREAMING TAMAMLANDI!\")\n",
        "        print(f\"‚è±Ô∏è Stream s√ºresi: {stream_time:.2f} saniye\")\n",
        "        print(f\"‚è±Ô∏è Toplam s√ºre: {(generation_time + stream_time):.2f} saniye\")\n",
        "        print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"‚ùå √úretim hatasƒ±: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        yield f\"data: {json.dumps({'error': error_msg, 'done': True})}\\n\\n\"\n",
        "\n",
        "    finally:\n",
        "        # Bellek temizliƒüi\n",
        "        print(\"üßπ Bellek temizliƒüi yapƒ±lƒ±yor...\")\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(\"‚úÖ Bellek temizlendi\")\n",
        "\n",
        "# ============================================================================\n",
        "# FLASK UYGULAMASI\n",
        "# ============================================================================\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/api/generate', methods=['POST'])\n",
        "def generate():\n",
        "    \"\"\"Streaming proje analizi endpoint'i\"\"\"\n",
        "    request_time = datetime.now()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(f\"üì• YENƒ∞ STREAMING ƒ∞STEK GELDƒ∞\")\n",
        "    print(f\"‚è∞ Zaman: {request_time.strftime('%H:%M:%S')}\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    try:\n",
        "        # Veri doƒürulama\n",
        "        print(\"üîç Veri doƒürulanƒ±yor...\")\n",
        "        data = request.get_json()\n",
        "\n",
        "        if not data:\n",
        "            print(\"‚ùå JSON girdisi bulunamadƒ±!\")\n",
        "            return jsonify({\"error\": \"JSON girdisi bulunamadƒ±\"}), 400\n",
        "\n",
        "        print(f\"‚úÖ JSON verisi alƒ±ndƒ± - Boyut: {len(str(data))} byte\")\n",
        "\n",
        "        json_input = data.get(\"json_input\")\n",
        "        project_key = data.get(\"project_key\", \"PROJECT\")\n",
        "\n",
        "        if not json_input:\n",
        "            print(\"‚ùå json_input alanƒ± eksik!\")\n",
        "            return jsonify({\"error\": \"json_input alanƒ± gerekli\"}), 400\n",
        "\n",
        "        print(f\"‚úÖ Proje anahtarƒ±: {project_key}\")\n",
        "        print(f\"‚úÖ Veri tipi: {type(json_input)}\")\n",
        "\n",
        "        # Eƒüer string ise parse et\n",
        "        if isinstance(json_input, str):\n",
        "            try:\n",
        "                json_input = json.loads(json_input)\n",
        "                print(\"‚úÖ JSON string parse edildi\")\n",
        "            except:\n",
        "                print(\"‚ö†Ô∏è JSON parse edilemedi, string olarak devam ediliyor\")\n",
        "\n",
        "        # Prompt olu≈ütur\n",
        "        prompt = create_analysis_prompt(json_input, project_key)\n",
        "\n",
        "        if prompt.startswith(\"‚ùå\"):\n",
        "            return jsonify({\"error\": prompt}), 400\n",
        "\n",
        "        # Streaming response d√∂nd√ºr\n",
        "        print(\"üöÄ Streaming response ba≈ülatƒ±lƒ±yor...\")\n",
        "        return Response(\n",
        "            stream_with_context(generate_streaming_response(prompt)),\n",
        "            mimetype='text/event-stream',\n",
        "            headers={\n",
        "                'Cache-Control': 'no-cache',\n",
        "                'X-Accel-Buffering': 'no',\n",
        "                'Connection': 'keep-alive',\n",
        "                'Access-Control-Allow-Origin': '*'\n",
        "            }\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå HATA OLU≈ûTU!\")\n",
        "        print(f\"Hata mesajƒ±: {str(e)}\")\n",
        "        import traceback\n",
        "        print(\"\\nüìã Stack trace:\")\n",
        "        traceback.print_exc()\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    \"\"\"Health check endpoint'i\"\"\"\n",
        "    print(f\"üíö Health check - {datetime.now().strftime('%H:%M:%S')}\")\n",
        "\n",
        "    try:\n",
        "        gpu_available = torch.cuda.is_available()\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3 if gpu_available else 0\n",
        "\n",
        "        return jsonify({\n",
        "            \"status\": \"healthy\",\n",
        "            \"model\": \"ytu-ce-cosmos/Turkish-Llama-8b-DPO-v0.1\",\n",
        "            \"gpu_available\": gpu_available,\n",
        "            \"gpu_memory_gb\": round(gpu_memory, 2),\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }), 200\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Health check hatasƒ±: {e}\")\n",
        "        return jsonify({\"status\": \"unhealthy\", \"error\": str(e)}), 500\n",
        "\n",
        "# ============================================================================\n",
        "# TEST ENDPOINTƒ∞ (Debug i√ßin)\n",
        "# ============================================================================\n",
        "@app.route('/api/test', methods=['GET'])\n",
        "def test():\n",
        "    \"\"\"Basit test endpoint'i\"\"\"\n",
        "    print(\"üß™ Test endpoint √ßaƒürƒ±ldƒ±\")\n",
        "\n",
        "    test_data = {\n",
        "        \"issues\": [\n",
        "            {\"key\": \"TEST-1\", \"status\": \"Done\", \"priority\": \"High\"},\n",
        "            {\"key\": \"TEST-2\", \"status\": \"In Progress\", \"priority\": \"Medium\"},\n",
        "            {\"key\": \"TEST-3\", \"status\": \"To Do\", \"priority\": \"Low\"}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    prompt = create_analysis_prompt(test_data, \"TEST\")\n",
        "\n",
        "    return Response(\n",
        "        stream_with_context(generate_streaming_response(prompt)),\n",
        "        mimetype='text/event-stream',\n",
        "        headers={'Cache-Control': 'no-cache', 'X-Accel-Buffering': 'no'}\n",
        "    )\n",
        "\n",
        "# ============================================================================\n",
        "# NGROK SETUP\n",
        "# ============================================================================\n",
        "try:\n",
        "    from pyngrok import ngrok\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"üåê NGROK BA≈ûLATILIYOR...\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    ngrok.kill()\n",
        "\n",
        "    public_url = ngrok.connect(5000)\n",
        "    print(f\"\\n‚úÖ API HAZIR!\")\n",
        "    print(f\"üì° Public URL: {public_url}\")\n",
        "    print(f\"\\nüîó Endpoints:\")\n",
        "    print(f\"   ‚Ä¢ Streaming: {public_url}/api/generate\")\n",
        "    print(f\"   ‚Ä¢ Test: {public_url}/api/test\")\n",
        "    print(f\"   ‚Ä¢ Health: {public_url}/health\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"\\n‚ö†Ô∏è pyngrok y√ºkl√º deƒüil. Local olarak √ßalƒ±≈üƒ±lƒ±yor.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Ngrok hatasƒ±: {e}\")\n",
        "\n",
        "# ============================================================================\n",
        "# SERVER BA≈ûLATMA\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üöÄ FLASK SERVER BA≈ûLATILIYOR...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000, threaded=True, debug=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdgEK3g-wttE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "035d9167529e4957a1214c331f4ba7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0958981fb55c4f22ab3e6c95b150d488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cb1f0a2c3074ed3b49669173863e91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0df87cb6227f4c408a3b2aca1a6f2e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38b5738753df4a80b83f78b4e0a00447",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bc5f7bf804648458237fc82bd9609f9",
            "value": 296
          }
        },
        "0f9e32a2a2424b8c828d2fbca80ffaeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13136ba2537140278819825bc851096f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc5f7bf804648458237fc82bd9609f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21ebcf507de347c29e90906c45c15ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c4979d7ca65461eb7eca4eb488a8b4a",
              "IPY_MODEL_ebc72b3cc8b24ea49343347e5a1470a1",
              "IPY_MODEL_4fb9aa7e934d461ca27d17e4b5957a66"
            ],
            "layout": "IPY_MODEL_89b52263350949fba500062965415930"
          }
        },
        "245ccd89ff59408a99317e8156c941c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27ca299386784598b82d51c62071cd09": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "291dd1efc1404186ba08d84db19053e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_520a55df250a44a09cb7291805fa5092",
              "IPY_MODEL_0df87cb6227f4c408a3b2aca1a6f2e2f",
              "IPY_MODEL_c1f66bd198e3456c876d25c26115c24f"
            ],
            "layout": "IPY_MODEL_8dc6ccc0d0254bfd9c3d0f372b34842e"
          }
        },
        "292f007303a84864a404e81a4f6b7cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355feb2c92284209b4d1181e78c85d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38b5738753df4a80b83f78b4e0a00447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3996038136af43a5986f47964104e456": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4cbb7b94ca463983616657ed97edfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4305909b07e3486fb20e61d1b1cbd8a9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_def91e3891cb4fbfbd787ce942aea1fd",
            "value": "tokenizer_config.json:‚Äá"
          }
        },
        "42693c5abef448f6b42b77d0ff4fb6da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4305909b07e3486fb20e61d1b1cbd8a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43c9e8f7408c4c27bc5e27b53386c6e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3996038136af43a5986f47964104e456",
            "max": 172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d213996ebd8f4772b553ff00665c8910",
            "value": 172
          }
        },
        "48a44eb3f1744dd7a7a45c95c6daa133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4962839be8694716b76fb62db25cd5a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d4cbb7b94ca463983616657ed97edfb",
              "IPY_MODEL_d38fa200fc824c39a6b26bcdfc28743e",
              "IPY_MODEL_67ffa802e2f84b039c6753208354c829"
            ],
            "layout": "IPY_MODEL_48a44eb3f1744dd7a7a45c95c6daa133"
          }
        },
        "4c40c4c2e4c844c39490a7c683176050": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb9aa7e934d461ca27d17e4b5957a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eacce3c626db42c3a734eca9041a1c3e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0cb1f0a2c3074ed3b49669173863e91e",
            "value": "‚Äá727/727‚Äá[00:00&lt;00:00,‚Äá97.6kB/s]"
          }
        },
        "4fed7721fb7149f581b7541fc5c9bbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87a130b5a6fa4ff9949f6dabe4416494",
              "IPY_MODEL_5f862aff15be4a498e1fc940abbe9300",
              "IPY_MODEL_bbe6597012d945afad7347b9ba85033c"
            ],
            "layout": "IPY_MODEL_f3ed0bd5bc0f4493b48fae8b7580d515"
          }
        },
        "520a55df250a44a09cb7291805fa5092": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_292f007303a84864a404e81a4f6b7cf8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_245ccd89ff59408a99317e8156c941c4",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "54b6e6e9dd6a421797f4394299ed9359": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ddc1fcf1582479b9af1333b343a05dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5f862aff15be4a498e1fc940abbe9300": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ddc1fcf1582479b9af1333b343a05dd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b10d53b6ce274636861d4eec023ef593",
            "value": 1
          }
        },
        "67ffa802e2f84b039c6753208354c829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81414790fbee440899d7546ad873e9ee",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b1ff947454694e3e90616eecd11e2a81",
            "value": "‚Äá51.0k/?‚Äá[00:00&lt;00:00,‚Äá5.80MB/s]"
          }
        },
        "6c4979d7ca65461eb7eca4eb488a8b4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13136ba2537140278819825bc851096f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7a51e251a2eb418ca55691c3eb145064",
            "value": "config.json:‚Äá100%"
          }
        },
        "6f2e7bc9eca440779df3190946ff50b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42693c5abef448f6b42b77d0ff4fb6da",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cb8c575af1334815bea9df25ed167e85",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "7296f47ddf8047abbef40f516fb49656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f2e7bc9eca440779df3190946ff50b6",
              "IPY_MODEL_43c9e8f7408c4c27bc5e27b53386c6e7",
              "IPY_MODEL_8714ac68b5f64761b94f083905c2cfaf"
            ],
            "layout": "IPY_MODEL_fa00e8b2516642dbbf74062972836a78"
          }
        },
        "7a51e251a2eb418ca55691c3eb145064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81414790fbee440899d7546ad873e9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8714ac68b5f64761b94f083905c2cfaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c40c4c2e4c844c39490a7c683176050",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_355feb2c92284209b4d1181e78c85d69",
            "value": "‚Äá172/172‚Äá[00:00&lt;00:00,‚Äá23.4kB/s]"
          }
        },
        "87a130b5a6fa4ff9949f6dabe4416494": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9e32a2a2424b8c828d2fbca80ffaeb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0958981fb55c4f22ab3e6c95b150d488",
            "value": "tokenizer.json:‚Äá"
          }
        },
        "89530df8d4df490a8b4697aae3e9ac1f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89b52263350949fba500062965415930": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dc6ccc0d0254bfd9c3d0f372b34842e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b2cb95c9a14e6ba577790db2616c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b10d53b6ce274636861d4eec023ef593": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1ff947454694e3e90616eecd11e2a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbe6597012d945afad7347b9ba85033c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ca299386784598b82d51c62071cd09",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_035d9167529e4957a1214c331f4ba7cd",
            "value": "‚Äá9.09M/?‚Äá[00:00&lt;00:00,‚Äá95.4MB/s]"
          }
        },
        "c1f66bd198e3456c876d25c26115c24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec24da979bdd4d56b50480168875d4c5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a3b2cb95c9a14e6ba577790db2616c6b",
            "value": "‚Äá296/296‚Äá[00:00&lt;00:00,‚Äá37.9kB/s]"
          }
        },
        "c47e9b64fb4543fe81c0873f658c32e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "c7ad1861c09140bbb1cf0e8813b736e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb8c575af1334815bea9df25ed167e85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d213996ebd8f4772b553ff00665c8910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d38fa200fc824c39a6b26bcdfc28743e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c47e9b64fb4543fe81c0873f658c32e8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7ad1861c09140bbb1cf0e8813b736e7",
            "value": 1
          }
        },
        "def91e3891cb4fbfbd787ce942aea1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eacce3c626db42c3a734eca9041a1c3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc72b3cc8b24ea49343347e5a1470a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89530df8d4df490a8b4697aae3e9ac1f",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54b6e6e9dd6a421797f4394299ed9359",
            "value": 727
          }
        },
        "ec24da979bdd4d56b50480168875d4c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ed0bd5bc0f4493b48fae8b7580d515": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa00e8b2516642dbbf74062972836a78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
